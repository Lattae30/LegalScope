{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from time import perf_counter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens(text):\n",
    "    return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "WORDS = Counter(tokens(open('').read()))\n",
    "\n",
    "def probability(word, N=SUM(WORDS.values())):\n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word):\n",
    "    'Most probable spelling correction for word.'\n",
    "    return max(candidates(word), key=probability)\n",
    "\n",
    "def candidates(word):\n",
    "    'Generate possible spelling corrections for word.'\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(tokens):\n",
    "    'The subset of `tokens` that appear in the dictionary of WORDS.'\n",
    "    return set(w for w in tokens if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'bulan juni'\n",
    "splits = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correction('kucink')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Code Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_tests():\n",
    "    assert correction('kalkulatf') == 'kalkulatif'              # insert\n",
    "    assert correction('mmandan') == 'memandang'           # replace 2\n",
    "    assert correction('minjadi') == 'menjadi'               # replace\n",
    "    assert correction('permusyawartn') == 'permusyawaratan'       # insert 2\n",
    "    assert correction('teersebut') == 'tersebut'            # delete\n",
    "    assert correction('naivgasi') =='navigasi'                  # transpose\n",
    "    assert correction('menginformasiknn') =='menginformasikan'                 # transpose + delete\n",
    "    assert correction('memang') == 'memang'                     # known\n",
    "    assert correction('sampan') == 'sampan' # unknown\n",
    "    assert tokens('Ini adalah sebuah TEST.') == ['ini', 'adalah', 'sebuah', 'test']\n",
    "    assert Counter(tokens('Ini adalah sebuah test. 123; sebuah TEST adalah ini.')) == (Counter({'123': 1, 'sebuah': 2, 'adalah': 2, 'test': 2, 'ini': 2}))\n",
    "    assert len(WORDS) == 432184\n",
    "    assert sum(WORDS.values()) == 4902106\n",
    "    assert WORDS.most_common(10) == [('yang', 151796),('dan', 109411),('di', 70168),('dengan', 54857),('itu', 51588), ('ini', 44693), ('tidak', 43062), ('untuk', 42823), ('dari', 41478), ('dalam', 39131)]\n",
    "    assert WORDS['yang'] == 151796\n",
    "    assert P('luring') == 0\n",
    "    assert 0.01 < P('yang') < 0.4\n",
    "    return 'unit_tests pass'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spelltest(tests, verbose=False):\n",
    "    \"Run correction(wrong) on all (right, wrong) pairs; report results.\"\n",
    "    start = perf_counter()\n",
    "    good, unknown = 0, 0\n",
    "    n = len(tests)\n",
    "    for right, wrong in tests:\n",
    "        w = correction(wrong)\n",
    "        good += (w == right)\n",
    "        if w != right:\n",
    "            unknown += (right not in WORDS)\n",
    "            if verbose:\n",
    "                print('correction({}) => {} ({}); expected {} ({})'\n",
    "                      .format(wrong, w, WORDS[w], right, WORDS[right]))\n",
    "    dt = perf_counter() - start\n",
    "    print('{:.0%} dari {} kata benar, ({:.0%} unknown) dengan {:.0f} kata per second '\n",
    "          .format(good / n, n, unknown / n, n / dt))\n",
    "    \n",
    "def Testset(lines):\n",
    "    \"Parse 'right: wrong1 wrong2' lines into [('right', 'wrong1'), ('right', 'wrong2')] pairs.\"\n",
    "    return [(right.lower(), wrong.lower())\n",
    "            for (right, wrongs) in (line.split(':') for line in lines)\n",
    "            for wrong in wrongs.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unit_tests())\n",
    "print(\"hasil Unigram : \")\n",
    "spelltest(Testset(open('/kaggle/input/mix-sentence-indonesia/spell-error.txt')), True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxGeV_mquzlO",
        "outputId": "40f095b4-00f1-4540-ed26-430f07e4e804"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.16.1)\n",
            "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.16.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (69.5.1)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
            "Requirement already satisfied: keras>=3.0.0 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.4.0)\n",
            "Requirement already satisfied: absl-py in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (2.1.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (1.26.4)\n",
            "Requirement already satisfied: rich in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (13.7.1)\n",
            "Requirement already satisfied: namex in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (3.11.0)\n",
            "Requirement already satisfied: optree in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (0.11.0)\n",
            "Requirement already satisfied: ml-dtypes in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (0.3.2)\n",
            "Requirement already satisfied: packaging in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras) (24.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optree->keras) (4.11.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras) (2.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\khalf\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install tensorflow\n",
        "%pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCWWA0_vueTt",
        "outputId": "8aa15417-7dd8-4f4d-f217-5329159341c9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\khalf\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "import json\n",
        "import nltk\n",
        "import string\n",
        "import random\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljmDL1RYu_Gd",
        "outputId": "3d5ad119-13d9-4a39-d88b-fc0f396b72a2"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/intents.json'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# read json file\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/content/intents.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m content:\n\u001b[0;32m      3\u001b[0m     chatbot \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(content)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#convert to dataframe\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\khalf\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/intents.json'"
          ]
        }
      ],
      "source": [
        "# read json file\n",
        "with open('/content/intents.json', 'r', encoding='utf-8') as content:\n",
        "    chatbot = json.load(content)\n",
        "\n",
        "#convert to dataframe\n",
        "data = pd.DataFrame(chatbot['intents'])\n",
        "\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "k1ueku88vYKC",
        "outputId": "9a0ab22b-952c-428d-8e66-7c0e5ba3dd92"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 18604,\n  \"fields\": [\n    {\n      \"column\": \"tag\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"qna 14\",\n          \"qna 40\",\n          \"qna 31\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"patterns\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 47,\n        \"samples\": [\n          \"s\",\n          \"2\",\n          \"l\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"responses\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-f72af422-a644-4e39-882b-8c4d4feba1c8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tag</th>\n",
              "      <th>patterns</th>\n",
              "      <th>responses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>qna 1</td>\n",
              "      <td>A</td>\n",
              "      <td>[Tujuan utama dari pembentukan Kitab Undang-Un...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>qna 1</td>\n",
              "      <td>p</td>\n",
              "      <td>[Tujuan utama dari pembentukan Kitab Undang-Un...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>qna 1</td>\n",
              "      <td>a</td>\n",
              "      <td>[Tujuan utama dari pembentukan Kitab Undang-Un...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>qna 1</td>\n",
              "      <td></td>\n",
              "      <td>[Tujuan utama dari pembentukan Kitab Undang-Un...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>qna 1</td>\n",
              "      <td>t</td>\n",
              "      <td>[Tujuan utama dari pembentukan Kitab Undang-Un...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18599</th>\n",
              "      <td>qna 50</td>\n",
              "      <td>u</td>\n",
              "      <td>[Berikut merupakan beberapa kasus tindak pidan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18600</th>\n",
              "      <td>qna 50</td>\n",
              "      <td>m</td>\n",
              "      <td>[Berikut merupakan beberapa kasus tindak pidan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18601</th>\n",
              "      <td>qna 50</td>\n",
              "      <td>u</td>\n",
              "      <td>[Berikut merupakan beberapa kasus tindak pidan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18602</th>\n",
              "      <td>qna 50</td>\n",
              "      <td>m</td>\n",
              "      <td>[Berikut merupakan beberapa kasus tindak pidan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18603</th>\n",
              "      <td>qna 50</td>\n",
              "      <td>?</td>\n",
              "      <td>[Berikut merupakan beberapa kasus tindak pidan...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18604 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f72af422-a644-4e39-882b-8c4d4feba1c8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f72af422-a644-4e39-882b-8c4d4feba1c8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f72af422-a644-4e39-882b-8c4d4feba1c8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-645a5629-0677-49d7-acbe-07bdc55a80b0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-645a5629-0677-49d7-acbe-07bdc55a80b0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-645a5629-0677-49d7-acbe-07bdc55a80b0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_0acef7e4-a1fe-4848-bc84-b129b27446ce\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0acef7e4-a1fe-4848-bc84-b129b27446ce button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          tag patterns                                          responses\n",
              "0       qna 1        A  [Tujuan utama dari pembentukan Kitab Undang-Un...\n",
              "1       qna 1        p  [Tujuan utama dari pembentukan Kitab Undang-Un...\n",
              "2       qna 1        a  [Tujuan utama dari pembentukan Kitab Undang-Un...\n",
              "3       qna 1           [Tujuan utama dari pembentukan Kitab Undang-Un...\n",
              "4       qna 1        t  [Tujuan utama dari pembentukan Kitab Undang-Un...\n",
              "...       ...      ...                                                ...\n",
              "18599  qna 50        u  [Berikut merupakan beberapa kasus tindak pidan...\n",
              "18600  qna 50        m  [Berikut merupakan beberapa kasus tindak pidan...\n",
              "18601  qna 50        u  [Berikut merupakan beberapa kasus tindak pidan...\n",
              "18602  qna 50        m  [Berikut merupakan beberapa kasus tindak pidan...\n",
              "18603  qna 50        ?  [Berikut merupakan beberapa kasus tindak pidan...\n",
              "\n",
              "[18604 rows x 3 columns]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#dictionary\n",
        "dictionary = {\"tag\": [], \"patterns\": [], \"responses\": []}\n",
        "\n",
        "#iterate trough the data\n",
        "for i in range (len(data)):\n",
        "  pattern = data[data.index==i]['patterns'].values[0]\n",
        "  response = data[data.index==i]['responses'].values[0]\n",
        "  tag = data[data.index==i]['tag'].values[0]\n",
        "  for j in range (len(pattern)):\n",
        "    dictionary['tag'].append(tag)\n",
        "    dictionary['patterns'].append((pattern[j]))\n",
        "    dictionary['responses'].append(response)\n",
        "\n",
        "#showing the data\n",
        "data = pd.DataFrame.from_dict(dictionary)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZxDi7cuvbpA",
        "outputId": "83c7ccc9-3557-48e8-8fd0-b42d5dbb1abe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     tag                                           patterns  \\\n",
            "0  qna 1  [Apa tujuan utama dari pembentukan Kitab Undan...   \n",
            "1  qna 2  [Apa yang dimaksud dengan Kitab Undang-Undang ...   \n",
            "2  qna 3  [Bagaimana ruang lingkup berlakunya ketentuan ...   \n",
            "3  qna 4  [Apa yang dimaksud dengan asas wilayah atau te...   \n",
            "4  qna 5  [Bagaimana ketentuan Pasal 2 ayat (1) dan (2) ...   \n",
            "\n",
            "                                           responses context  \n",
            "0  [Tujuan utama dari pembentukan Kitab Undang-Un...      []  \n",
            "1  [Kitab Undang-Undang Hukum Pidana (KUHP) adala...      []  \n",
            "2  [Ketentuan peraturan Perundang-undangan hukum ...      []  \n",
            "3  [Asas wilayah atau teritorial adalah asas hubu...      []  \n",
            "4  [Hukum yang hidup dalam masyarakat yang terdap...      []  \n"
          ]
        }
      ],
      "source": [
        "with open('/content/questionVal.json', 'r', encoding='utf-8') as content:\n",
        "    val_chatbot = json.load(content)\n",
        "val_data = pd.DataFrame(val_chatbot['intents'])\n",
        "\n",
        "print(val_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "JIE0pjOcvnSD",
        "outputId": "b4d5eff7-f628-4562-d246-09fe5c1b7226"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"val_data\",\n  \"rows\": 4627,\n  \"fields\": [\n    {\n      \"column\": \"tag\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"qna 14\",\n          \"qna 40\",\n          \"qna 31\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"patterns\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 45,\n        \"samples\": [\n          \"2\",\n          \"M\",\n          \"l\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "val_data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-fae8be68-8486-4dd7-b039-d28b0936cd34\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tag</th>\n",
              "      <th>patterns</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>qna 1</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>qna 1</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>qna 1</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>qna 1</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>qna 1</td>\n",
              "      <td>t</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4622</th>\n",
              "      <td>qna 50</td>\n",
              "      <td>h</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4623</th>\n",
              "      <td>qna 50</td>\n",
              "      <td>u</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4624</th>\n",
              "      <td>qna 50</td>\n",
              "      <td>s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4625</th>\n",
              "      <td>qna 50</td>\n",
              "      <td>u</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4626</th>\n",
              "      <td>qna 50</td>\n",
              "      <td>s</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4627 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fae8be68-8486-4dd7-b039-d28b0936cd34')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fae8be68-8486-4dd7-b039-d28b0936cd34 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fae8be68-8486-4dd7-b039-d28b0936cd34');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5b7e1de2-94ac-448a-9e41-4651f84653c5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5b7e1de2-94ac-448a-9e41-4651f84653c5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5b7e1de2-94ac-448a-9e41-4651f84653c5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_3ee06eff-fc83-44e1-b821-22de4de47fe4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('val_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3ee06eff-fc83-44e1-b821-22de4de47fe4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('val_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         tag patterns\n",
              "0      qna 1        A\n",
              "1      qna 1        p\n",
              "2      qna 1        a\n",
              "3      qna 1         \n",
              "4      qna 1        t\n",
              "...      ...      ...\n",
              "4622  qna 50        h\n",
              "4623  qna 50        u\n",
              "4624  qna 50        s\n",
              "4625  qna 50        u\n",
              "4626  qna 50        s\n",
              "\n",
              "[4627 rows x 2 columns]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#dictionaries\n",
        "dictionariez = {\"tag\":[], \"patterns\":[]}\n",
        "\n",
        "for i in range (len(val_data)):\n",
        "  pattern = val_data[val_data.index==i]['patterns'].values[0]\n",
        "  tag = val_data[val_data.index==i]['tag'].values[0]\n",
        "  for j in range (len(pattern)):\n",
        "    dictionariez['tag'].append(tag)\n",
        "    dictionariez['patterns'].append(pattern[j])\n",
        "\n",
        "val_data = pd.DataFrame.from_dict(dictionariez)\n",
        "val_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSecVBkhvpYu",
        "outputId": "52862bd4-38eb-4c07-87a8-dffdc8c9ec74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['qna 1', 'qna 2', 'qna 3', 'qna 4', 'qna 5', 'qna 6', 'qna 7',\n",
              "       'qna 8', 'qna 9', 'qna 10', 'qna 11', 'qna 12', 'qna 13', 'qna 14',\n",
              "       'qna 15', 'qna 16', 'qna 17', 'qna 18', 'qna 19', 'qna 20',\n",
              "       'qna 21', 'qna 22', 'qna 23', 'qna 24', 'qna 25', 'qna 26',\n",
              "       'qna 27', 'qna 28', 'qna 29', 'qna 30', 'qna 31', 'qna 32',\n",
              "       'qna 33', 'qna 34', 'qna 35', 'qna 36', 'qna 37', 'qna 38',\n",
              "       'qna 39', 'qna 40', 'qna 41', 'qna 42', 'qna 43', 'qna 44',\n",
              "       'qna 45', 'qna 46', 'qna 47', 'qna 48', 'qna 49', 'qna 50'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Training\n",
        "data['tag'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAZaR-Q3vysS",
        "outputId": "2872ae40-e9d5-45c4-e4f1-1e7019ca179f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18727\n"
          ]
        }
      ],
      "source": [
        "#Tokenizing and Validation Patterns\n",
        "with open('/content/dictionaries.json', 'r') as f:\n",
        "  json_dict = json.load(f)\n",
        "\n",
        "tokenizer_json = json_dict.keys()\n",
        "\n",
        "tokenizer = Tokenizer(oov_token = '')\n",
        "tokenizer.fit_on_texts(tokenizer_json)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print(len(word_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "het1rexSwkP-"
      },
      "outputs": [],
      "source": [
        "#shuffling data\n",
        "data = shuffle(data)\n",
        "\n",
        "val_data = shuffle(val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBAdVqK9wtfm",
        "outputId": "cc81a5a5-2f01-40c7-f94b-b5c8c25d72c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Input Shape :  (282, 12)\n",
            "12\n",
            "Training Label Shape :  (282,)\n",
            "Num of classes:  50\n"
          ]
        }
      ],
      "source": [
        "#encoding labels\n",
        "label_encode = LabelEncoder()\n",
        "\n",
        "tokenizer.fit_on_texts(data['patterns'])\n",
        "tokenizer.fit_on_texts(val_data['patterns'])\n",
        "\n",
        "#trainin sets\n",
        "pattern_train = tokenizer.texts_to_sequences(data['patterns'])\n",
        "x_train = pad_sequences(pattern_train, padding='post', maxlen=12, truncating='pre')\n",
        "print(\"Training Input Shape : \", x_train.shape)\n",
        "print(len(x_train[0]))\n",
        "\n",
        "x_label = label_encode.fit_transform(data['tag'])\n",
        "print(\"Training Label Shape : \", x_label.shape)\n",
        "print(\"Num of classes: \", len(np.unique(x_label)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZpAmHUawyhH",
        "outputId": "3864c63a-a0ff-494b-b4bc-5d0d7493a1a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Input Shape :  (71, 12)\n",
            "12\n",
            "Validation Label Shape :  (71,)\n",
            "Num of classes:  50\n"
          ]
        }
      ],
      "source": [
        "#validation\n",
        "pattern_val = tokenizer.texts_to_sequences(val_data['patterns'])\n",
        "y_train = pad_sequences(pattern_val, padding='post', maxlen=12, truncating='pre')\n",
        "print(\"Validation Input Shape : \", y_train.shape)\n",
        "print(len(y_train[0]))\n",
        "\n",
        "y_label = label_encode.fit_transform(val_data['tag'])\n",
        "print(\"Validation Label Shape : \",y_label.shape)\n",
        "print(\"Num of classes: \", len(np.unique(y_label)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2F9tBzKxKPE",
        "outputId": "1e1a924d-b592-44c3-cf53-347ed23dbf9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number unique word :  18764\n",
            "Output Length :  50\n"
          ]
        }
      ],
      "source": [
        "vocabulary = len(tokenizer.word_index)\n",
        "print(\"Number unique word : \",vocabulary)\n",
        "print(\"Output Length : \", label_encode.classes_.shape[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-i8g_HWxMxc"
      },
      "outputs": [],
      "source": [
        "word_dictionary = {item[0]: item[1] for item in tokenizer.word_index.items()}\n",
        "with open('tokenizer_chatbot_dict.json', 'w') as json_file:\n",
        "  json.dump(word_dictionary, json_file, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vM8i41gHxPH4"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Label encoding for 'tag' column in val_data\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(val_data['tag'])\n",
        "\n",
        "# Convert numpy.int64 to native Python int\n",
        "class_labels = label_encoder.classes_.tolist()\n",
        "class_indices = label_encoder.transform(label_encoder.classes_).tolist()\n",
        "label_mapping = {label: int(idx) for label, idx in zip(class_labels, class_indices)}\n",
        "\n",
        "# Write the mapping dictionary to a JSON file\n",
        "with open('label_decoder.json', 'w') as file:\n",
        "    json.dump(label_mapping, file, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kn_1ustJzPby",
        "outputId": "56e97212-fd5f-49b4-90a1-1150282d08ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-06-27 17:45:35--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2024-06-27 17:45:35--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.02MB/s    in 2m 39s  \n",
            "\n",
            "2024-06-27 17:48:14 (5.19 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ],
      "source": [
        "# !rm -f glove.6B.zip\n",
        "!wget https://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfGJJRkezjJC",
        "outputId": "9d305037-74d6-4d69-d226-ab87e27d04b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "400000\n"
          ]
        }
      ],
      "source": [
        "glove_dir = \"/content/glove.6B.100d.txt\"\n",
        "embeddings_index = {}\n",
        "file_ = open(glove_dir, encoding='utf8')\n",
        "for line in file_:\n",
        "  arr = line.split()\n",
        "  single_word = arr[0]\n",
        "  w = np.asarray(arr[1:],dtype='float32')\n",
        "  embeddings_index[single_word] = w\n",
        "file_.close()\n",
        "print(len(embeddings_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JfgVzpt0Q7O"
      },
      "outputs": [],
      "source": [
        "max = vocabulary + 1\n",
        "word_index =tokenizer.word_index\n",
        "embedding_mat = np.zeros((max, 100)).astype(object)\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_mat[i] = embedding_vector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z90_-Njz0UsG"
      },
      "outputs": [],
      "source": [
        "def chatbot_test():\n",
        "    while True:\n",
        "        user_input = input(\"User: \").lower()\n",
        "        # Tokenize and pad the user input\n",
        "        tokenized_input = tokenizer.texts_to_sequences([user_input])\n",
        "        x_test = pad_sequences(tokenized_input, maxlen=x_train.shape[1])\n",
        "\n",
        "        # Predict the response\n",
        "        prediction = model.predict(x_test)[0]\n",
        "        label = label_encode.inverse_transform([np.argmax(prediction)])[0]\n",
        "\n",
        "        # Select a response based on the predicted label\n",
        "        responses = data[data['tag'] == label]['responses'].values[0]\n",
        "        print(\"Label:\", label)\n",
        "        print(\"Chatbot:\", random.choice(responses))\n",
        "\n",
        "        # Break the loop if the label is 'qna 1' or 'qna 2'\n",
        "        if label == 'qna 1' or label == 'qna 2':\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASPNtdj_0jfp"
      },
      "outputs": [],
      "source": [
        "def plot_training_history(history):\n",
        "    # Plotting training accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy', color='blue')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='green')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Accuracy')\n",
        "    plt.ylim(0, 1.0)\n",
        "\n",
        "    # Plotting training loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss', color='orange')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss', color='yellow')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Loss')\n",
        "    plt.ylim(0, 4.0)\n",
        "\n",
        "    # Display the plots\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSXMcPnU0omM",
        "outputId": "f6c843c1-1c0e-451e-ef8f-0f7ca858e008"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 12, 100)           1876500   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 12, 100)           0         \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 12, 128)           87936     \n",
            "                                                                 \n",
            " layer_normalization (Layer  (None, 12, 128)           256       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 12, 128)           0         \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 128)               98688     \n",
            "                                                                 \n",
            " layer_normalization_1 (Lay  (None, 128)               256       \n",
            " erNormalization)                                                \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               33024     \n",
            "                                                                 \n",
            " layer_normalization_2 (Lay  (None, 256)               512       \n",
            " erNormalization)                                                \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " layer_normalization_3 (Lay  (None, 128)               256       \n",
            " erNormalization)                                                \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 50)                6450      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2136774 (8.15 MB)\n",
            "Trainable params: 260274 (1016.70 KB)\n",
            "Non-trainable params: 1876500 (7.16 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(x_train.shape[1])),\n",
        "    tf.keras.layers.Embedding(input_dim=vocabulary+1, output_dim = 100, mask_zero=True,\n",
        "                              weights=[embedding_mat], trainable=False),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "    tf.keras.layers.GRU(128, return_sequences=True, reset_after=False),\n",
        "    tf.keras.layers.LayerNormalization(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.GRU(128, return_sequences=False, reset_after=False),\n",
        "    tf.keras.layers.LayerNormalization(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.LayerNormalization(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.LayerNormalization(),\n",
        "    tf.keras.layers.Dense(len(np.unique(x_label)), activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "np4v_84w0tZ7"
      },
      "outputs": [],
      "source": [
        "# Callback function to stop training when the accuracy is above 90%\n",
        "# and validation accuracy above 90%\n",
        "class MyCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if logs.get('accuracy') > 0.9 and logs.get('val_accuracy') > 0.8:\n",
        "            self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhOd0e0G0xrd",
        "outputId": "b8bfdeb5-ac34-45a7-c1b0-59481f78e7bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "9/9 [==============================] - 8s 138ms/step - loss: 4.3680 - accuracy: 0.0532 - val_loss: 3.2154 - val_accuracy: 0.2113\n",
            "Epoch 2/1000\n",
            "9/9 [==============================] - 0s 52ms/step - loss: 3.6544 - accuracy: 0.0922 - val_loss: 2.5632 - val_accuracy: 0.4085\n",
            "Epoch 3/1000\n",
            "9/9 [==============================] - 0s 52ms/step - loss: 3.1087 - accuracy: 0.2340 - val_loss: 2.1175 - val_accuracy: 0.4507\n",
            "Epoch 4/1000\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 2.8072 - accuracy: 0.2979 - val_loss: 1.7800 - val_accuracy: 0.5634\n",
            "Epoch 5/1000\n",
            "9/9 [==============================] - 0s 48ms/step - loss: 2.5589 - accuracy: 0.3333 - val_loss: 1.5558 - val_accuracy: 0.6056\n",
            "Epoch 6/1000\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 2.3633 - accuracy: 0.3546 - val_loss: 1.3881 - val_accuracy: 0.6479\n",
            "Epoch 7/1000\n",
            "9/9 [==============================] - 0s 49ms/step - loss: 2.2658 - accuracy: 0.4113 - val_loss: 1.2941 - val_accuracy: 0.6620\n",
            "Epoch 8/1000\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 2.1426 - accuracy: 0.4539 - val_loss: 1.1419 - val_accuracy: 0.6901\n",
            "Epoch 9/1000\n",
            "9/9 [==============================] - 0s 48ms/step - loss: 2.0643 - accuracy: 0.4468 - val_loss: 1.0442 - val_accuracy: 0.6761\n",
            "Epoch 10/1000\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 1.8828 - accuracy: 0.4787 - val_loss: 1.0277 - val_accuracy: 0.6620\n",
            "Epoch 11/1000\n",
            "9/9 [==============================] - 0s 52ms/step - loss: 1.9150 - accuracy: 0.4752 - val_loss: 0.9370 - val_accuracy: 0.7042\n",
            "Epoch 12/1000\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 1.7957 - accuracy: 0.4929 - val_loss: 0.8858 - val_accuracy: 0.7324\n",
            "Epoch 13/1000\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 1.7695 - accuracy: 0.5248 - val_loss: 0.8900 - val_accuracy: 0.7324\n",
            "Epoch 14/1000\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 1.7238 - accuracy: 0.4858 - val_loss: 0.8504 - val_accuracy: 0.7465\n",
            "Epoch 15/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.6591 - accuracy: 0.5496 - val_loss: 0.7885 - val_accuracy: 0.7746\n",
            "Epoch 16/1000\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 1.5876 - accuracy: 0.5355 - val_loss: 0.7626 - val_accuracy: 0.7746\n",
            "Epoch 17/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.5964 - accuracy: 0.5035 - val_loss: 0.7164 - val_accuracy: 0.7465\n",
            "Epoch 18/1000\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 1.5640 - accuracy: 0.5213 - val_loss: 0.6976 - val_accuracy: 0.7746\n",
            "Epoch 19/1000\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 1.5530 - accuracy: 0.5284 - val_loss: 0.6745 - val_accuracy: 0.7606\n",
            "Epoch 20/1000\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 1.5271 - accuracy: 0.5355 - val_loss: 0.6426 - val_accuracy: 0.7887\n",
            "Epoch 21/1000\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 1.5257 - accuracy: 0.5284 - val_loss: 0.6271 - val_accuracy: 0.7746\n",
            "Epoch 22/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.4415 - accuracy: 0.5603 - val_loss: 0.6298 - val_accuracy: 0.7746\n",
            "Epoch 23/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 1.4439 - accuracy: 0.5532 - val_loss: 0.5765 - val_accuracy: 0.8169\n",
            "Epoch 24/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.3777 - accuracy: 0.5567 - val_loss: 0.5830 - val_accuracy: 0.8169\n",
            "Epoch 25/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.3626 - accuracy: 0.5887 - val_loss: 0.5850 - val_accuracy: 0.8028\n",
            "Epoch 26/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.3186 - accuracy: 0.5674 - val_loss: 0.5692 - val_accuracy: 0.8028\n",
            "Epoch 27/1000\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 1.3385 - accuracy: 0.5780 - val_loss: 0.5731 - val_accuracy: 0.8028\n",
            "Epoch 28/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.3101 - accuracy: 0.5638 - val_loss: 0.5520 - val_accuracy: 0.8169\n",
            "Epoch 29/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.2787 - accuracy: 0.5993 - val_loss: 0.5143 - val_accuracy: 0.8028\n",
            "Epoch 30/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.3112 - accuracy: 0.5887 - val_loss: 0.5054 - val_accuracy: 0.8028\n",
            "Epoch 31/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.2522 - accuracy: 0.6064 - val_loss: 0.5093 - val_accuracy: 0.8169\n",
            "Epoch 32/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.1587 - accuracy: 0.6277 - val_loss: 0.5176 - val_accuracy: 0.8169\n",
            "Epoch 33/1000\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 1.2283 - accuracy: 0.6099 - val_loss: 0.5047 - val_accuracy: 0.8169\n",
            "Epoch 34/1000\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 1.2450 - accuracy: 0.6028 - val_loss: 0.4724 - val_accuracy: 0.8310\n",
            "Epoch 35/1000\n",
            "9/9 [==============================] - 0s 51ms/step - loss: 1.1761 - accuracy: 0.6028 - val_loss: 0.4738 - val_accuracy: 0.7887\n",
            "Epoch 36/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 1.1983 - accuracy: 0.6135 - val_loss: 0.4621 - val_accuracy: 0.8169\n",
            "Epoch 37/1000\n",
            "9/9 [==============================] - 0s 51ms/step - loss: 1.2117 - accuracy: 0.5993 - val_loss: 0.4885 - val_accuracy: 0.8028\n",
            "Epoch 38/1000\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 1.2303 - accuracy: 0.6277 - val_loss: 0.5070 - val_accuracy: 0.8028\n",
            "Epoch 39/1000\n",
            "9/9 [==============================] - 0s 49ms/step - loss: 1.1603 - accuracy: 0.6170 - val_loss: 0.4827 - val_accuracy: 0.8169\n",
            "Epoch 40/1000\n",
            "9/9 [==============================] - 0s 52ms/step - loss: 1.1632 - accuracy: 0.6206 - val_loss: 0.4437 - val_accuracy: 0.8310\n",
            "Epoch 41/1000\n",
            "9/9 [==============================] - 0s 49ms/step - loss: 1.1527 - accuracy: 0.5957 - val_loss: 0.4356 - val_accuracy: 0.8451\n",
            "Epoch 42/1000\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 1.1269 - accuracy: 0.6277 - val_loss: 0.4139 - val_accuracy: 0.8310\n",
            "Epoch 43/1000\n",
            "9/9 [==============================] - 0s 48ms/step - loss: 1.1481 - accuracy: 0.6312 - val_loss: 0.4273 - val_accuracy: 0.8169\n",
            "Epoch 44/1000\n",
            "9/9 [==============================] - 0s 56ms/step - loss: 1.1155 - accuracy: 0.6631 - val_loss: 0.4228 - val_accuracy: 0.8310\n",
            "Epoch 45/1000\n",
            "9/9 [==============================] - 0s 52ms/step - loss: 1.0536 - accuracy: 0.6418 - val_loss: 0.3858 - val_accuracy: 0.8732\n",
            "Epoch 46/1000\n",
            "9/9 [==============================] - 0s 51ms/step - loss: 1.0865 - accuracy: 0.6277 - val_loss: 0.3983 - val_accuracy: 0.8451\n",
            "Epoch 47/1000\n",
            "9/9 [==============================] - 0s 51ms/step - loss: 1.0604 - accuracy: 0.6489 - val_loss: 0.4070 - val_accuracy: 0.8169\n",
            "Epoch 48/1000\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 1.0274 - accuracy: 0.6809 - val_loss: 0.4511 - val_accuracy: 0.7887\n",
            "Epoch 49/1000\n",
            "9/9 [==============================] - 0s 51ms/step - loss: 1.1264 - accuracy: 0.6312 - val_loss: 0.4557 - val_accuracy: 0.8310\n",
            "Epoch 50/1000\n",
            "9/9 [==============================] - 0s 52ms/step - loss: 1.1431 - accuracy: 0.6383 - val_loss: 0.3845 - val_accuracy: 0.8732\n",
            "Epoch 51/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 1.0592 - accuracy: 0.6454 - val_loss: 0.4228 - val_accuracy: 0.8310\n",
            "Epoch 52/1000\n",
            "9/9 [==============================] - 0s 52ms/step - loss: 1.0731 - accuracy: 0.6418 - val_loss: 0.4282 - val_accuracy: 0.8451\n",
            "Epoch 53/1000\n",
            "9/9 [==============================] - 0s 50ms/step - loss: 0.9865 - accuracy: 0.6738 - val_loss: 0.4043 - val_accuracy: 0.8451\n",
            "Epoch 54/1000\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 1.0238 - accuracy: 0.6418 - val_loss: 0.4056 - val_accuracy: 0.8310\n",
            "Epoch 55/1000\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.9958 - accuracy: 0.6667 - val_loss: 0.3701 - val_accuracy: 0.8310\n",
            "Epoch 56/1000\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.9677 - accuracy: 0.6702 - val_loss: 0.3747 - val_accuracy: 0.8169\n",
            "Epoch 57/1000\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.0011 - accuracy: 0.6383 - val_loss: 0.3664 - val_accuracy: 0.8451\n",
            "Epoch 58/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.9789 - accuracy: 0.6879 - val_loss: 0.3407 - val_accuracy: 0.8732\n",
            "Epoch 59/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.9501 - accuracy: 0.6667 - val_loss: 0.3480 - val_accuracy: 0.8451\n",
            "Epoch 60/1000\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.9411 - accuracy: 0.6667 - val_loss: 0.3532 - val_accuracy: 0.8451\n",
            "Epoch 61/1000\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.9034 - accuracy: 0.6844 - val_loss: 0.3334 - val_accuracy: 0.8451\n",
            "Epoch 62/1000\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.8864 - accuracy: 0.6879 - val_loss: 0.3297 - val_accuracy: 0.8592\n",
            "Epoch 63/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.9010 - accuracy: 0.6879 - val_loss: 0.3463 - val_accuracy: 0.8451\n",
            "Epoch 64/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8697 - accuracy: 0.6844 - val_loss: 0.3193 - val_accuracy: 0.8592\n",
            "Epoch 65/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.9130 - accuracy: 0.6986 - val_loss: 0.3346 - val_accuracy: 0.8732\n",
            "Epoch 66/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.9060 - accuracy: 0.6809 - val_loss: 0.3384 - val_accuracy: 0.8451\n",
            "Epoch 67/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.9296 - accuracy: 0.6560 - val_loss: 0.3471 - val_accuracy: 0.8451\n",
            "Epoch 68/1000\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.8930 - accuracy: 0.6738 - val_loss: 0.3316 - val_accuracy: 0.8451\n",
            "Epoch 69/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.8805 - accuracy: 0.6950 - val_loss: 0.3180 - val_accuracy: 0.8451\n",
            "Epoch 70/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.9041 - accuracy: 0.6879 - val_loss: 0.3277 - val_accuracy: 0.8451\n",
            "Epoch 71/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8671 - accuracy: 0.6950 - val_loss: 0.3259 - val_accuracy: 0.8451\n",
            "Epoch 72/1000\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.8962 - accuracy: 0.6844 - val_loss: 0.3162 - val_accuracy: 0.8592\n",
            "Epoch 73/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8580 - accuracy: 0.7092 - val_loss: 0.3128 - val_accuracy: 0.8451\n",
            "Epoch 74/1000\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.8766 - accuracy: 0.6879 - val_loss: 0.3101 - val_accuracy: 0.8732\n",
            "Epoch 75/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8981 - accuracy: 0.6773 - val_loss: 0.3326 - val_accuracy: 0.8451\n",
            "Epoch 76/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.8820 - accuracy: 0.6738 - val_loss: 0.3134 - val_accuracy: 0.8451\n",
            "Epoch 77/1000\n",
            "9/9 [==============================] - 0s 49ms/step - loss: 0.8460 - accuracy: 0.6950 - val_loss: 0.2998 - val_accuracy: 0.8732\n",
            "Epoch 78/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.8875 - accuracy: 0.6631 - val_loss: 0.3184 - val_accuracy: 0.8592\n",
            "Epoch 79/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.8121 - accuracy: 0.7092 - val_loss: 0.3480 - val_accuracy: 0.8310\n",
            "Epoch 80/1000\n",
            "9/9 [==============================] - 1s 50ms/step - loss: 0.8298 - accuracy: 0.7057 - val_loss: 0.3221 - val_accuracy: 0.8451\n",
            "Epoch 81/1000\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 0.8525 - accuracy: 0.7021 - val_loss: 0.3034 - val_accuracy: 0.8592\n",
            "Epoch 82/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.8270 - accuracy: 0.6844 - val_loss: 0.2864 - val_accuracy: 0.8873\n",
            "Epoch 83/1000\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.7932 - accuracy: 0.7092 - val_loss: 0.2874 - val_accuracy: 0.8873\n",
            "Epoch 84/1000\n",
            "9/9 [==============================] - 0s 50ms/step - loss: 0.8128 - accuracy: 0.7163 - val_loss: 0.2886 - val_accuracy: 0.8732\n",
            "Epoch 85/1000\n",
            "9/9 [==============================] - 0s 50ms/step - loss: 0.8102 - accuracy: 0.6986 - val_loss: 0.2945 - val_accuracy: 0.8451\n",
            "Epoch 86/1000\n",
            "9/9 [==============================] - 0s 51ms/step - loss: 0.7818 - accuracy: 0.7128 - val_loss: 0.2795 - val_accuracy: 0.8592\n",
            "Epoch 87/1000\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 0.7877 - accuracy: 0.7199 - val_loss: 0.2835 - val_accuracy: 0.8592\n",
            "Epoch 88/1000\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.8010 - accuracy: 0.6986 - val_loss: 0.2868 - val_accuracy: 0.8732\n",
            "Epoch 89/1000\n",
            "9/9 [==============================] - 0s 48ms/step - loss: 0.8012 - accuracy: 0.7021 - val_loss: 0.2885 - val_accuracy: 0.8592\n",
            "Epoch 90/1000\n",
            "9/9 [==============================] - 0s 51ms/step - loss: 0.7873 - accuracy: 0.7021 - val_loss: 0.3038 - val_accuracy: 0.8592\n",
            "Epoch 91/1000\n",
            "9/9 [==============================] - 0s 48ms/step - loss: 0.7958 - accuracy: 0.6950 - val_loss: 0.3516 - val_accuracy: 0.8310\n",
            "Epoch 92/1000\n",
            "9/9 [==============================] - 0s 56ms/step - loss: 0.7987 - accuracy: 0.6950 - val_loss: 0.2799 - val_accuracy: 0.8732\n",
            "Epoch 93/1000\n",
            "9/9 [==============================] - 0s 48ms/step - loss: 0.8029 - accuracy: 0.7199 - val_loss: 0.3077 - val_accuracy: 0.8451\n",
            "Epoch 94/1000\n",
            "9/9 [==============================] - 0s 50ms/step - loss: 0.7818 - accuracy: 0.7199 - val_loss: 0.2804 - val_accuracy: 0.8592\n",
            "Epoch 95/1000\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 0.7746 - accuracy: 0.7234 - val_loss: 0.2747 - val_accuracy: 0.8732\n",
            "Epoch 96/1000\n",
            "9/9 [==============================] - 1s 68ms/step - loss: 0.7738 - accuracy: 0.7092 - val_loss: 0.2629 - val_accuracy: 0.8732\n",
            "Epoch 97/1000\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.7416 - accuracy: 0.7376 - val_loss: 0.2808 - val_accuracy: 0.8732\n",
            "Epoch 98/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.7776 - accuracy: 0.7057 - val_loss: 0.2742 - val_accuracy: 0.8732\n",
            "Epoch 99/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7995 - accuracy: 0.7057 - val_loss: 0.3017 - val_accuracy: 0.8451\n",
            "Epoch 100/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7800 - accuracy: 0.7021 - val_loss: 0.2845 - val_accuracy: 0.8732\n",
            "Epoch 101/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7831 - accuracy: 0.7128 - val_loss: 0.2834 - val_accuracy: 0.8592\n",
            "Epoch 102/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7063 - accuracy: 0.7553 - val_loss: 0.2780 - val_accuracy: 0.8592\n",
            "Epoch 103/1000\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.7455 - accuracy: 0.7270 - val_loss: 0.2707 - val_accuracy: 0.8732\n",
            "Epoch 104/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7464 - accuracy: 0.7305 - val_loss: 0.2777 - val_accuracy: 0.8451\n",
            "Epoch 105/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.7446 - accuracy: 0.7340 - val_loss: 0.2688 - val_accuracy: 0.8592\n",
            "Epoch 106/1000\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.7533 - accuracy: 0.7199 - val_loss: 0.2776 - val_accuracy: 0.8592\n",
            "Epoch 107/1000\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.7413 - accuracy: 0.7305 - val_loss: 0.2881 - val_accuracy: 0.8592\n",
            "Epoch 108/1000\n",
            "9/9 [==============================] - 1s 125ms/step - loss: 0.7311 - accuracy: 0.7340 - val_loss: 0.2719 - val_accuracy: 0.8732\n",
            "Epoch 109/1000\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.7731 - accuracy: 0.6879 - val_loss: 0.2869 - val_accuracy: 0.8592\n",
            "Epoch 110/1000\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.7429 - accuracy: 0.7270 - val_loss: 0.2629 - val_accuracy: 0.8873\n",
            "Epoch 111/1000\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.7415 - accuracy: 0.7411 - val_loss: 0.2664 - val_accuracy: 0.8592\n",
            "Epoch 112/1000\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.7313 - accuracy: 0.7199 - val_loss: 0.2712 - val_accuracy: 0.8732\n",
            "Epoch 113/1000\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7503 - accuracy: 0.7057 - val_loss: 0.2840 - val_accuracy: 0.8592\n",
            "Epoch 114/1000\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.6897 - accuracy: 0.7730 - val_loss: 0.2984 - val_accuracy: 0.8451\n",
            "Epoch 115/1000\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.7090 - accuracy: 0.7270 - val_loss: 0.2810 - val_accuracy: 0.8592\n",
            "Epoch 116/1000\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.7065 - accuracy: 0.7305 - val_loss: 0.2750 - val_accuracy: 0.8592\n",
            "Epoch 117/1000\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.7031 - accuracy: 0.7376 - val_loss: 0.2814 - val_accuracy: 0.8732\n",
            "Epoch 118/1000\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7297 - accuracy: 0.7234 - val_loss: 0.2649 - val_accuracy: 0.8732\n",
            "Epoch 119/1000\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.6993 - accuracy: 0.7234 - val_loss: 0.2981 - val_accuracy: 0.8592\n",
            "Epoch 120/1000\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.7365 - accuracy: 0.7163 - val_loss: 0.2887 - val_accuracy: 0.8451\n",
            "Epoch 121/1000\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.7022 - accuracy: 0.7057 - val_loss: 0.2850 - val_accuracy: 0.8592\n",
            "Epoch 122/1000\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.7501 - accuracy: 0.6986 - val_loss: 0.2852 - val_accuracy: 0.8451\n",
            "Epoch 123/1000\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7427 - accuracy: 0.7092 - val_loss: 0.2682 - val_accuracy: 0.8592\n",
            "Epoch 124/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6929 - accuracy: 0.7411 - val_loss: 0.2787 - val_accuracy: 0.8732\n",
            "Epoch 125/1000\n",
            "9/9 [==============================] - 1s 128ms/step - loss: 0.6741 - accuracy: 0.7411 - val_loss: 0.2783 - val_accuracy: 0.8451\n",
            "Epoch 126/1000\n",
            "9/9 [==============================] - 1s 138ms/step - loss: 0.7215 - accuracy: 0.7305 - val_loss: 0.2802 - val_accuracy: 0.8732\n",
            "Epoch 127/1000\n",
            "9/9 [==============================] - 3s 381ms/step - loss: 0.6762 - accuracy: 0.7340 - val_loss: 0.2831 - val_accuracy: 0.8592\n",
            "Epoch 128/1000\n",
            "9/9 [==============================] - 2s 235ms/step - loss: 0.6842 - accuracy: 0.7340 - val_loss: 0.2893 - val_accuracy: 0.8451\n",
            "Epoch 129/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7116 - accuracy: 0.7199 - val_loss: 0.2847 - val_accuracy: 0.8451\n",
            "Epoch 130/1000\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6334 - accuracy: 0.7553 - val_loss: 0.2752 - val_accuracy: 0.8732\n",
            "Epoch 131/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.7104 - accuracy: 0.7234 - val_loss: 0.2722 - val_accuracy: 0.8732\n",
            "Epoch 132/1000\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.6660 - accuracy: 0.7376 - val_loss: 0.2609 - val_accuracy: 0.8732\n",
            "Epoch 133/1000\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.6624 - accuracy: 0.7589 - val_loss: 0.2680 - val_accuracy: 0.8732\n",
            "Epoch 134/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6860 - accuracy: 0.7340 - val_loss: 0.2848 - val_accuracy: 0.8592\n",
            "Epoch 135/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6755 - accuracy: 0.7270 - val_loss: 0.2749 - val_accuracy: 0.8592\n",
            "Epoch 136/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6627 - accuracy: 0.7305 - val_loss: 0.2528 - val_accuracy: 0.8732\n",
            "Epoch 137/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6865 - accuracy: 0.7411 - val_loss: 0.2731 - val_accuracy: 0.8732\n",
            "Epoch 138/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6861 - accuracy: 0.7092 - val_loss: 0.2645 - val_accuracy: 0.8732\n",
            "Epoch 139/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6648 - accuracy: 0.7305 - val_loss: 0.2977 - val_accuracy: 0.8310\n",
            "Epoch 140/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6831 - accuracy: 0.7128 - val_loss: 0.2660 - val_accuracy: 0.8592\n",
            "Epoch 141/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6811 - accuracy: 0.7411 - val_loss: 0.2589 - val_accuracy: 0.8873\n",
            "Epoch 142/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6868 - accuracy: 0.7234 - val_loss: 0.2809 - val_accuracy: 0.8732\n",
            "Epoch 143/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6594 - accuracy: 0.7340 - val_loss: 0.2761 - val_accuracy: 0.8451\n",
            "Epoch 144/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6764 - accuracy: 0.7128 - val_loss: 0.2654 - val_accuracy: 0.8592\n",
            "Epoch 145/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6835 - accuracy: 0.7128 - val_loss: 0.2633 - val_accuracy: 0.8732\n",
            "Epoch 146/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6615 - accuracy: 0.7163 - val_loss: 0.2682 - val_accuracy: 0.8732\n",
            "Epoch 147/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6467 - accuracy: 0.7589 - val_loss: 0.2865 - val_accuracy: 0.8592\n",
            "Epoch 148/1000\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.6315 - accuracy: 0.7411 - val_loss: 0.2695 - val_accuracy: 0.8451\n",
            "Epoch 149/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6395 - accuracy: 0.7376 - val_loss: 0.2582 - val_accuracy: 0.8732\n",
            "Epoch 150/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6803 - accuracy: 0.7199 - val_loss: 0.2601 - val_accuracy: 0.8732\n",
            "Epoch 151/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6522 - accuracy: 0.7163 - val_loss: 0.2735 - val_accuracy: 0.8592\n",
            "Epoch 152/1000\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.6812 - accuracy: 0.7128 - val_loss: 0.2773 - val_accuracy: 0.8451\n",
            "Epoch 153/1000\n",
            "9/9 [==============================] - 0s 49ms/step - loss: 0.6549 - accuracy: 0.7128 - val_loss: 0.2840 - val_accuracy: 0.8592\n",
            "Epoch 154/1000\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.6499 - accuracy: 0.7305 - val_loss: 0.2761 - val_accuracy: 0.8592\n",
            "Epoch 155/1000\n",
            "9/9 [==============================] - 0s 49ms/step - loss: 0.6523 - accuracy: 0.7092 - val_loss: 0.2596 - val_accuracy: 0.8732\n",
            "Epoch 156/1000\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.6520 - accuracy: 0.7340 - val_loss: 0.2680 - val_accuracy: 0.8732\n",
            "Epoch 157/1000\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 0.6446 - accuracy: 0.7305 - val_loss: 0.2780 - val_accuracy: 0.8732\n",
            "Epoch 158/1000\n",
            "9/9 [==============================] - 0s 56ms/step - loss: 0.6558 - accuracy: 0.7340 - val_loss: 0.2723 - val_accuracy: 0.8592\n",
            "Epoch 159/1000\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 0.6346 - accuracy: 0.7234 - val_loss: 0.2743 - val_accuracy: 0.8451\n",
            "Epoch 160/1000\n",
            "9/9 [==============================] - 0s 56ms/step - loss: 0.6619 - accuracy: 0.7518 - val_loss: 0.2813 - val_accuracy: 0.8451\n",
            "Epoch 161/1000\n",
            "9/9 [==============================] - 0s 52ms/step - loss: 0.6584 - accuracy: 0.7234 - val_loss: 0.2729 - val_accuracy: 0.8592\n",
            "Epoch 162/1000\n",
            "9/9 [==============================] - 0s 57ms/step - loss: 0.6489 - accuracy: 0.7376 - val_loss: 0.2863 - val_accuracy: 0.8451\n",
            "Epoch 163/1000\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 0.6345 - accuracy: 0.7340 - val_loss: 0.2655 - val_accuracy: 0.8732\n",
            "Epoch 164/1000\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.6574 - accuracy: 0.7305 - val_loss: 0.2722 - val_accuracy: 0.8732\n",
            "Epoch 165/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.6449 - accuracy: 0.7518 - val_loss: 0.2830 - val_accuracy: 0.8451\n",
            "Epoch 166/1000\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 0.6395 - accuracy: 0.7270 - val_loss: 0.2763 - val_accuracy: 0.8592\n",
            "Epoch 167/1000\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.6505 - accuracy: 0.7411 - val_loss: 0.2569 - val_accuracy: 0.8732\n",
            "Epoch 168/1000\n",
            "9/9 [==============================] - 0s 56ms/step - loss: 0.6734 - accuracy: 0.6986 - val_loss: 0.2664 - val_accuracy: 0.8592\n",
            "Epoch 169/1000\n",
            "9/9 [==============================] - 0s 51ms/step - loss: 0.6631 - accuracy: 0.7199 - val_loss: 0.2675 - val_accuracy: 0.8592\n",
            "Epoch 170/1000\n",
            "9/9 [==============================] - 0s 52ms/step - loss: 0.6339 - accuracy: 0.7447 - val_loss: 0.2538 - val_accuracy: 0.8592\n",
            "Epoch 171/1000\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.6572 - accuracy: 0.7305 - val_loss: 0.2782 - val_accuracy: 0.8451\n",
            "Epoch 172/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.6759 - accuracy: 0.7234 - val_loss: 0.2415 - val_accuracy: 0.8732\n",
            "Epoch 173/1000\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 0.6863 - accuracy: 0.7128 - val_loss: 0.2875 - val_accuracy: 0.8310\n",
            "Epoch 174/1000\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.6481 - accuracy: 0.7518 - val_loss: 0.2516 - val_accuracy: 0.8732\n",
            "Epoch 175/1000\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.6706 - accuracy: 0.7163 - val_loss: 0.3048 - val_accuracy: 0.8310\n",
            "Epoch 176/1000\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.6823 - accuracy: 0.7234 - val_loss: 0.2573 - val_accuracy: 0.8451\n",
            "Epoch 177/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6485 - accuracy: 0.7305 - val_loss: 0.2665 - val_accuracy: 0.8592\n",
            "Epoch 178/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6501 - accuracy: 0.7199 - val_loss: 0.2693 - val_accuracy: 0.8451\n",
            "Epoch 179/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6289 - accuracy: 0.7270 - val_loss: 0.2872 - val_accuracy: 0.8451\n",
            "Epoch 180/1000\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.6443 - accuracy: 0.7270 - val_loss: 0.2919 - val_accuracy: 0.8451\n",
            "Epoch 181/1000\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.6301 - accuracy: 0.7482 - val_loss: 0.2738 - val_accuracy: 0.8592\n",
            "Epoch 182/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5875 - accuracy: 0.7234 - val_loss: 0.2611 - val_accuracy: 0.8732\n",
            "Epoch 183/1000\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.6328 - accuracy: 0.7518 - val_loss: 0.2687 - val_accuracy: 0.8592\n",
            "Epoch 184/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6256 - accuracy: 0.7270 - val_loss: 0.2696 - val_accuracy: 0.8732\n",
            "Epoch 185/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6024 - accuracy: 0.7270 - val_loss: 0.2773 - val_accuracy: 0.8451\n",
            "Epoch 186/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6161 - accuracy: 0.7305 - val_loss: 0.2617 - val_accuracy: 0.8732\n",
            "Epoch 187/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6181 - accuracy: 0.7305 - val_loss: 0.2597 - val_accuracy: 0.8592\n",
            "Epoch 188/1000\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.6008 - accuracy: 0.7234 - val_loss: 0.2579 - val_accuracy: 0.8592\n",
            "Epoch 189/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6294 - accuracy: 0.7340 - val_loss: 0.2516 - val_accuracy: 0.8732\n",
            "Epoch 190/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6284 - accuracy: 0.7234 - val_loss: 0.2572 - val_accuracy: 0.8732\n",
            "Epoch 191/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6552 - accuracy: 0.7128 - val_loss: 0.2679 - val_accuracy: 0.8451\n",
            "Epoch 192/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6214 - accuracy: 0.7340 - val_loss: 0.2748 - val_accuracy: 0.8310\n",
            "Epoch 193/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6237 - accuracy: 0.7305 - val_loss: 0.2694 - val_accuracy: 0.8592\n",
            "Epoch 194/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6101 - accuracy: 0.7411 - val_loss: 0.2545 - val_accuracy: 0.8732\n",
            "Epoch 195/1000\n",
            "9/9 [==============================] - 1s 67ms/step - loss: 0.6320 - accuracy: 0.7270 - val_loss: 0.2641 - val_accuracy: 0.8732\n",
            "Epoch 196/1000\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 0.6064 - accuracy: 0.7482 - val_loss: 0.2603 - val_accuracy: 0.8592\n",
            "Epoch 197/1000\n",
            "9/9 [==============================] - 0s 52ms/step - loss: 0.6250 - accuracy: 0.7128 - val_loss: 0.2640 - val_accuracy: 0.8732\n",
            "Epoch 198/1000\n",
            "9/9 [==============================] - 0s 57ms/step - loss: 0.6037 - accuracy: 0.7624 - val_loss: 0.2638 - val_accuracy: 0.8732\n",
            "Epoch 199/1000\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.6004 - accuracy: 0.7234 - val_loss: 0.2567 - val_accuracy: 0.8732\n",
            "Epoch 200/1000\n",
            "9/9 [==============================] - 0s 52ms/step - loss: 0.6171 - accuracy: 0.7234 - val_loss: 0.2584 - val_accuracy: 0.8873\n",
            "Epoch 201/1000\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 0.6169 - accuracy: 0.7376 - val_loss: 0.2558 - val_accuracy: 0.8592\n",
            "Epoch 202/1000\n",
            "9/9 [==============================] - 0s 52ms/step - loss: 0.6277 - accuracy: 0.7340 - val_loss: 0.2659 - val_accuracy: 0.8732\n",
            "Epoch 203/1000\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.6135 - accuracy: 0.7305 - val_loss: 0.2705 - val_accuracy: 0.8732\n",
            "Epoch 204/1000\n",
            "9/9 [==============================] - 0s 50ms/step - loss: 0.6150 - accuracy: 0.7411 - val_loss: 0.2834 - val_accuracy: 0.8592\n",
            "Epoch 205/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.6711 - accuracy: 0.6950 - val_loss: 0.2552 - val_accuracy: 0.8873\n",
            "Epoch 206/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.6244 - accuracy: 0.7305 - val_loss: 0.2707 - val_accuracy: 0.8592\n",
            "Epoch 207/1000\n",
            "9/9 [==============================] - 0s 56ms/step - loss: 0.5988 - accuracy: 0.7553 - val_loss: 0.2603 - val_accuracy: 0.8732\n",
            "Epoch 208/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.6092 - accuracy: 0.7447 - val_loss: 0.2749 - val_accuracy: 0.8310\n",
            "Epoch 209/1000\n",
            "9/9 [==============================] - 1s 60ms/step - loss: 0.6008 - accuracy: 0.7340 - val_loss: 0.2621 - val_accuracy: 0.8732\n",
            "Epoch 210/1000\n",
            "9/9 [==============================] - 0s 51ms/step - loss: 0.6088 - accuracy: 0.7270 - val_loss: 0.2592 - val_accuracy: 0.8592\n",
            "Epoch 211/1000\n",
            "9/9 [==============================] - 0s 56ms/step - loss: 0.6075 - accuracy: 0.7447 - val_loss: 0.2707 - val_accuracy: 0.8451\n",
            "Epoch 212/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.6358 - accuracy: 0.7199 - val_loss: 0.2711 - val_accuracy: 0.8592\n",
            "Epoch 213/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.6075 - accuracy: 0.7305 - val_loss: 0.2676 - val_accuracy: 0.8592\n",
            "Epoch 214/1000\n",
            "9/9 [==============================] - 0s 49ms/step - loss: 0.6620 - accuracy: 0.7092 - val_loss: 0.2785 - val_accuracy: 0.8451\n",
            "Epoch 215/1000\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.6075 - accuracy: 0.7376 - val_loss: 0.2604 - val_accuracy: 0.8732\n",
            "Epoch 216/1000\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.6313 - accuracy: 0.7411 - val_loss: 0.2626 - val_accuracy: 0.8732\n",
            "Epoch 217/1000\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.5902 - accuracy: 0.7376 - val_loss: 0.2646 - val_accuracy: 0.8592\n",
            "Epoch 218/1000\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.5976 - accuracy: 0.7305 - val_loss: 0.2808 - val_accuracy: 0.8451\n",
            "Epoch 219/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6213 - accuracy: 0.7340 - val_loss: 0.2693 - val_accuracy: 0.8451\n",
            "Epoch 220/1000\n",
            "9/9 [==============================] - 2s 196ms/step - loss: 0.6243 - accuracy: 0.7234 - val_loss: 0.2599 - val_accuracy: 0.8732\n",
            "Epoch 221/1000\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.6030 - accuracy: 0.7340 - val_loss: 0.2542 - val_accuracy: 0.8732\n",
            "Epoch 222/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6065 - accuracy: 0.7270 - val_loss: 0.2646 - val_accuracy: 0.8732\n",
            "Epoch 223/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6293 - accuracy: 0.7234 - val_loss: 0.2549 - val_accuracy: 0.8592\n",
            "Epoch 224/1000\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.6193 - accuracy: 0.7128 - val_loss: 0.2643 - val_accuracy: 0.8592\n",
            "Epoch 225/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5728 - accuracy: 0.7660 - val_loss: 0.2618 - val_accuracy: 0.8592\n",
            "Epoch 226/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5844 - accuracy: 0.7411 - val_loss: 0.2652 - val_accuracy: 0.8310\n",
            "Epoch 227/1000\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5832 - accuracy: 0.7624 - val_loss: 0.2675 - val_accuracy: 0.8592\n",
            "Epoch 228/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6150 - accuracy: 0.7376 - val_loss: 0.2670 - val_accuracy: 0.8451\n",
            "Epoch 229/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5904 - accuracy: 0.7411 - val_loss: 0.2594 - val_accuracy: 0.8592\n",
            "Epoch 230/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6197 - accuracy: 0.7270 - val_loss: 0.2588 - val_accuracy: 0.8732\n",
            "Epoch 231/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6055 - accuracy: 0.7411 - val_loss: 0.2578 - val_accuracy: 0.8732\n",
            "Epoch 232/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6081 - accuracy: 0.7270 - val_loss: 0.2507 - val_accuracy: 0.8732\n",
            "Epoch 233/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6159 - accuracy: 0.7376 - val_loss: 0.2693 - val_accuracy: 0.8732\n",
            "Epoch 234/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6260 - accuracy: 0.7270 - val_loss: 0.2519 - val_accuracy: 0.8732\n",
            "Epoch 235/1000\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.6106 - accuracy: 0.7305 - val_loss: 0.2810 - val_accuracy: 0.8451\n",
            "Epoch 236/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.5954 - accuracy: 0.7411 - val_loss: 0.2765 - val_accuracy: 0.8451\n",
            "Epoch 237/1000\n",
            "9/9 [==============================] - 0s 50ms/step - loss: 0.6089 - accuracy: 0.7482 - val_loss: 0.2592 - val_accuracy: 0.8592\n",
            "Epoch 238/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.6107 - accuracy: 0.7234 - val_loss: 0.2605 - val_accuracy: 0.8592\n",
            "Epoch 239/1000\n",
            "9/9 [==============================] - 0s 51ms/step - loss: 0.6157 - accuracy: 0.7199 - val_loss: 0.2793 - val_accuracy: 0.8451\n",
            "Epoch 240/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.5962 - accuracy: 0.7411 - val_loss: 0.2660 - val_accuracy: 0.8592\n",
            "Epoch 241/1000\n",
            "9/9 [==============================] - 0s 50ms/step - loss: 0.6099 - accuracy: 0.7305 - val_loss: 0.2621 - val_accuracy: 0.8592\n",
            "Epoch 242/1000\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.5959 - accuracy: 0.7482 - val_loss: 0.2666 - val_accuracy: 0.8592\n",
            "Epoch 243/1000\n",
            "9/9 [==============================] - 0s 52ms/step - loss: 0.6166 - accuracy: 0.7305 - val_loss: 0.2504 - val_accuracy: 0.8873\n",
            "Epoch 244/1000\n",
            "9/9 [==============================] - 0s 50ms/step - loss: 0.6264 - accuracy: 0.7128 - val_loss: 0.2574 - val_accuracy: 0.8451\n",
            "Epoch 245/1000\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.6412 - accuracy: 0.7376 - val_loss: 0.2528 - val_accuracy: 0.8451\n",
            "Epoch 246/1000\n",
            "9/9 [==============================] - 0s 50ms/step - loss: 0.6867 - accuracy: 0.6809 - val_loss: 0.2767 - val_accuracy: 0.8592\n",
            "Epoch 247/1000\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.6345 - accuracy: 0.7021 - val_loss: 0.2703 - val_accuracy: 0.8451\n",
            "Epoch 248/1000\n",
            "9/9 [==============================] - 0s 56ms/step - loss: 0.6212 - accuracy: 0.7270 - val_loss: 0.2754 - val_accuracy: 0.8592\n",
            "Epoch 249/1000\n",
            "9/9 [==============================] - 0s 56ms/step - loss: 0.6166 - accuracy: 0.7376 - val_loss: 0.2655 - val_accuracy: 0.8451\n",
            "Epoch 250/1000\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.6011 - accuracy: 0.7305 - val_loss: 0.2678 - val_accuracy: 0.8451\n",
            "Epoch 251/1000\n",
            "9/9 [==============================] - 0s 57ms/step - loss: 0.6059 - accuracy: 0.7163 - val_loss: 0.2740 - val_accuracy: 0.8310\n",
            "Epoch 252/1000\n",
            "9/9 [==============================] - 0s 51ms/step - loss: 0.6413 - accuracy: 0.7128 - val_loss: 0.2822 - val_accuracy: 0.8592\n",
            "Epoch 253/1000\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.6289 - accuracy: 0.7057 - val_loss: 0.2779 - val_accuracy: 0.8451\n",
            "Epoch 254/1000\n",
            "9/9 [==============================] - 0s 52ms/step - loss: 0.5900 - accuracy: 0.7518 - val_loss: 0.2837 - val_accuracy: 0.8451\n",
            "Epoch 255/1000\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.5941 - accuracy: 0.7411 - val_loss: 0.2643 - val_accuracy: 0.8732\n",
            "Epoch 256/1000\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.5822 - accuracy: 0.7589 - val_loss: 0.2702 - val_accuracy: 0.8451\n",
            "Epoch 257/1000\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.5950 - accuracy: 0.7482 - val_loss: 0.2723 - val_accuracy: 0.8310\n",
            "Epoch 258/1000\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.5751 - accuracy: 0.7411 - val_loss: 0.2676 - val_accuracy: 0.8592\n",
            "Epoch 259/1000\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.5978 - accuracy: 0.7270 - val_loss: 0.2643 - val_accuracy: 0.8732\n",
            "Epoch 260/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5934 - accuracy: 0.7376 - val_loss: 0.2567 - val_accuracy: 0.8732\n",
            "Epoch 261/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6148 - accuracy: 0.7270 - val_loss: 0.2659 - val_accuracy: 0.8451\n",
            "Epoch 262/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5957 - accuracy: 0.7447 - val_loss: 0.2614 - val_accuracy: 0.8732\n",
            "Epoch 263/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6012 - accuracy: 0.7092 - val_loss: 0.2692 - val_accuracy: 0.8451\n",
            "Epoch 264/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5887 - accuracy: 0.7340 - val_loss: 0.2666 - val_accuracy: 0.8451\n",
            "Epoch 265/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6009 - accuracy: 0.7340 - val_loss: 0.2682 - val_accuracy: 0.8451\n",
            "Epoch 266/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5994 - accuracy: 0.7199 - val_loss: 0.2674 - val_accuracy: 0.8451\n",
            "Epoch 267/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5984 - accuracy: 0.7340 - val_loss: 0.2555 - val_accuracy: 0.8592\n",
            "Epoch 268/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5734 - accuracy: 0.7376 - val_loss: 0.2561 - val_accuracy: 0.8732\n",
            "Epoch 269/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5839 - accuracy: 0.7376 - val_loss: 0.2627 - val_accuracy: 0.8451\n",
            "Epoch 270/1000\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5950 - accuracy: 0.7305 - val_loss: 0.2689 - val_accuracy: 0.8310\n",
            "Epoch 271/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5796 - accuracy: 0.7411 - val_loss: 0.2652 - val_accuracy: 0.8451\n",
            "Epoch 272/1000\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.5898 - accuracy: 0.7270 - val_loss: 0.2673 - val_accuracy: 0.8451\n",
            "Epoch 273/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5631 - accuracy: 0.7518 - val_loss: 0.2528 - val_accuracy: 0.8732\n",
            "Epoch 274/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5741 - accuracy: 0.7411 - val_loss: 0.2588 - val_accuracy: 0.8732\n",
            "Epoch 275/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5704 - accuracy: 0.7270 - val_loss: 0.2612 - val_accuracy: 0.8592\n",
            "Epoch 276/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6039 - accuracy: 0.7411 - val_loss: 0.2639 - val_accuracy: 0.8310\n",
            "Epoch 277/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5877 - accuracy: 0.7270 - val_loss: 0.2674 - val_accuracy: 0.8310\n",
            "Epoch 278/1000\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 0.5850 - accuracy: 0.7482 - val_loss: 0.2690 - val_accuracy: 0.8451\n",
            "Epoch 279/1000\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 0.6047 - accuracy: 0.7057 - val_loss: 0.2731 - val_accuracy: 0.8310\n",
            "Epoch 280/1000\n",
            "9/9 [==============================] - 0s 51ms/step - loss: 0.5829 - accuracy: 0.7447 - val_loss: 0.2664 - val_accuracy: 0.8310\n",
            "Epoch 281/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.5804 - accuracy: 0.7199 - val_loss: 0.2695 - val_accuracy: 0.8451\n",
            "Epoch 282/1000\n",
            "9/9 [==============================] - 0s 52ms/step - loss: 0.5897 - accuracy: 0.7411 - val_loss: 0.2609 - val_accuracy: 0.8732\n",
            "Epoch 283/1000\n",
            "9/9 [==============================] - 0s 57ms/step - loss: 0.6114 - accuracy: 0.6986 - val_loss: 0.2701 - val_accuracy: 0.8451\n",
            "Epoch 284/1000\n",
            "9/9 [==============================] - 0s 56ms/step - loss: 0.5662 - accuracy: 0.7518 - val_loss: 0.2650 - val_accuracy: 0.8451\n",
            "Epoch 285/1000\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.5772 - accuracy: 0.7447 - val_loss: 0.2564 - val_accuracy: 0.8873\n",
            "Epoch 286/1000\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 0.5971 - accuracy: 0.7199 - val_loss: 0.2572 - val_accuracy: 0.8732\n",
            "Epoch 287/1000\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.5897 - accuracy: 0.7234 - val_loss: 0.2645 - val_accuracy: 0.8451\n",
            "Epoch 288/1000\n",
            "9/9 [==============================] - 0s 52ms/step - loss: 0.5596 - accuracy: 0.7447 - val_loss: 0.2645 - val_accuracy: 0.8451\n",
            "Epoch 289/1000\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 0.6072 - accuracy: 0.7270 - val_loss: 0.2653 - val_accuracy: 0.8592\n",
            "Epoch 290/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.5827 - accuracy: 0.7376 - val_loss: 0.2609 - val_accuracy: 0.8732\n",
            "Epoch 291/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.5910 - accuracy: 0.7234 - val_loss: 0.2735 - val_accuracy: 0.8451\n",
            "Epoch 292/1000\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.5798 - accuracy: 0.7730 - val_loss: 0.2683 - val_accuracy: 0.8451\n",
            "Epoch 293/1000\n",
            "9/9 [==============================] - 1s 77ms/step - loss: 0.5899 - accuracy: 0.7376 - val_loss: 0.2577 - val_accuracy: 0.8592\n",
            "Epoch 294/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.5918 - accuracy: 0.7128 - val_loss: 0.2675 - val_accuracy: 0.8310\n",
            "Epoch 295/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.5909 - accuracy: 0.7482 - val_loss: 0.2514 - val_accuracy: 0.8732\n",
            "Epoch 296/1000\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.5674 - accuracy: 0.7482 - val_loss: 0.2633 - val_accuracy: 0.8592\n",
            "Epoch 297/1000\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.5911 - accuracy: 0.7305 - val_loss: 0.2679 - val_accuracy: 0.8451\n",
            "Epoch 298/1000\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.5956 - accuracy: 0.7163 - val_loss: 0.2744 - val_accuracy: 0.8451\n",
            "Epoch 299/1000\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.5788 - accuracy: 0.7447 - val_loss: 0.2675 - val_accuracy: 0.8451\n",
            "Epoch 300/1000\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.5661 - accuracy: 0.7482 - val_loss: 0.2576 - val_accuracy: 0.8732\n",
            "Epoch 301/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5883 - accuracy: 0.7305 - val_loss: 0.2613 - val_accuracy: 0.8732\n",
            "Epoch 302/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5740 - accuracy: 0.7305 - val_loss: 0.2656 - val_accuracy: 0.8732\n",
            "Epoch 303/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5666 - accuracy: 0.7376 - val_loss: 0.2633 - val_accuracy: 0.8592\n",
            "Epoch 304/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5789 - accuracy: 0.7305 - val_loss: 0.2593 - val_accuracy: 0.8592\n",
            "Epoch 305/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5715 - accuracy: 0.7411 - val_loss: 0.2605 - val_accuracy: 0.8592\n",
            "Epoch 306/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5776 - accuracy: 0.7340 - val_loss: 0.2629 - val_accuracy: 0.8310\n",
            "Epoch 307/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5814 - accuracy: 0.7482 - val_loss: 0.2693 - val_accuracy: 0.8310\n",
            "Epoch 308/1000\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6064 - accuracy: 0.7128 - val_loss: 0.2669 - val_accuracy: 0.8592\n",
            "Epoch 309/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5882 - accuracy: 0.7305 - val_loss: 0.2634 - val_accuracy: 0.8592\n",
            "Epoch 310/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5705 - accuracy: 0.7270 - val_loss: 0.2654 - val_accuracy: 0.8732\n",
            "Epoch 311/1000\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.5762 - accuracy: 0.7447 - val_loss: 0.2613 - val_accuracy: 0.8732\n",
            "Epoch 312/1000\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5773 - accuracy: 0.7376 - val_loss: 0.2507 - val_accuracy: 0.9014\n",
            "Epoch 313/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5596 - accuracy: 0.7695 - val_loss: 0.2628 - val_accuracy: 0.8732\n",
            "Epoch 314/1000\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.5682 - accuracy: 0.7730 - val_loss: 0.2627 - val_accuracy: 0.8732\n",
            "Epoch 315/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5878 - accuracy: 0.7234 - val_loss: 0.2755 - val_accuracy: 0.8310\n",
            "Epoch 316/1000\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.5730 - accuracy: 0.7340 - val_loss: 0.2738 - val_accuracy: 0.8451\n",
            "Epoch 317/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5842 - accuracy: 0.7305 - val_loss: 0.2615 - val_accuracy: 0.8451\n",
            "Epoch 318/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6016 - accuracy: 0.7376 - val_loss: 0.2750 - val_accuracy: 0.8310\n",
            "Epoch 319/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5653 - accuracy: 0.7411 - val_loss: 0.2789 - val_accuracy: 0.8310\n",
            "Epoch 320/1000\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.5874 - accuracy: 0.7340 - val_loss: 0.2713 - val_accuracy: 0.8592\n",
            "Epoch 321/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.5918 - accuracy: 0.7128 - val_loss: 0.2694 - val_accuracy: 0.8732\n",
            "Epoch 322/1000\n",
            "9/9 [==============================] - 0s 56ms/step - loss: 0.5790 - accuracy: 0.7340 - val_loss: 0.2622 - val_accuracy: 0.8732\n",
            "Epoch 323/1000\n",
            "9/9 [==============================] - 0s 51ms/step - loss: 0.5945 - accuracy: 0.7270 - val_loss: 0.2587 - val_accuracy: 0.8873\n",
            "Epoch 324/1000\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.5865 - accuracy: 0.7021 - val_loss: 0.2602 - val_accuracy: 0.8592\n",
            "Epoch 325/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.5742 - accuracy: 0.7482 - val_loss: 0.2611 - val_accuracy: 0.8592\n",
            "Epoch 326/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.5747 - accuracy: 0.7340 - val_loss: 0.2631 - val_accuracy: 0.8592\n",
            "Epoch 327/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.5700 - accuracy: 0.7305 - val_loss: 0.2801 - val_accuracy: 0.8451\n",
            "Epoch 328/1000\n",
            "9/9 [==============================] - 1s 60ms/step - loss: 0.6002 - accuracy: 0.7163 - val_loss: 0.2769 - val_accuracy: 0.8451\n",
            "Epoch 329/1000\n",
            "9/9 [==============================] - 0s 50ms/step - loss: 0.5735 - accuracy: 0.7199 - val_loss: 0.2697 - val_accuracy: 0.8451\n",
            "Epoch 330/1000\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.5870 - accuracy: 0.7482 - val_loss: 0.2632 - val_accuracy: 0.8592\n",
            "Epoch 331/1000\n",
            "9/9 [==============================] - 0s 50ms/step - loss: 0.5799 - accuracy: 0.7199 - val_loss: 0.2659 - val_accuracy: 0.8310\n",
            "Epoch 332/1000\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.5668 - accuracy: 0.7376 - val_loss: 0.2641 - val_accuracy: 0.8592\n",
            "Epoch 333/1000\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.5818 - accuracy: 0.7305 - val_loss: 0.2519 - val_accuracy: 0.8873\n",
            "Epoch 334/1000\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.5705 - accuracy: 0.7553 - val_loss: 0.2548 - val_accuracy: 0.8873\n",
            "Epoch 335/1000\n",
            "9/9 [==============================] - 0s 49ms/step - loss: 0.5819 - accuracy: 0.7199 - val_loss: 0.2680 - val_accuracy: 0.8451\n",
            "Epoch 336/1000\n",
            "9/9 [==============================] - 1s 60ms/step - loss: 0.5773 - accuracy: 0.7305 - val_loss: 0.2705 - val_accuracy: 0.8451\n",
            "Epoch 337/1000\n",
            "9/9 [==============================] - 0s 51ms/step - loss: 0.5736 - accuracy: 0.7234 - val_loss: 0.2645 - val_accuracy: 0.8592\n",
            "Epoch 338/1000\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.5672 - accuracy: 0.7234 - val_loss: 0.2586 - val_accuracy: 0.8873\n",
            "Epoch 339/1000\n",
            "9/9 [==============================] - 0s 50ms/step - loss: 0.5603 - accuracy: 0.7411 - val_loss: 0.2601 - val_accuracy: 0.8732\n",
            "Epoch 340/1000\n",
            "9/9 [==============================] - 0s 57ms/step - loss: 0.5710 - accuracy: 0.7270 - val_loss: 0.2621 - val_accuracy: 0.8732\n",
            "Epoch 341/1000\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.5714 - accuracy: 0.7376 - val_loss: 0.2635 - val_accuracy: 0.8592\n",
            "Epoch 342/1000\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.5531 - accuracy: 0.7589 - val_loss: 0.2622 - val_accuracy: 0.8732\n",
            "Epoch 343/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5705 - accuracy: 0.7589 - val_loss: 0.2550 - val_accuracy: 0.8873\n",
            "Epoch 344/1000\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.5725 - accuracy: 0.7234 - val_loss: 0.2521 - val_accuracy: 0.8592\n",
            "Epoch 345/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5831 - accuracy: 0.7199 - val_loss: 0.2584 - val_accuracy: 0.8592\n",
            "Epoch 346/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5613 - accuracy: 0.7482 - val_loss: 0.2610 - val_accuracy: 0.8451\n",
            "Epoch 347/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5484 - accuracy: 0.7624 - val_loss: 0.2641 - val_accuracy: 0.8451\n",
            "Epoch 348/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5888 - accuracy: 0.7234 - val_loss: 0.2694 - val_accuracy: 0.8451\n",
            "Epoch 349/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5675 - accuracy: 0.7518 - val_loss: 0.2737 - val_accuracy: 0.8451\n",
            "Epoch 350/1000\n",
            "9/9 [==============================] - 1s 177ms/step - loss: 0.5863 - accuracy: 0.7092 - val_loss: 0.2793 - val_accuracy: 0.8310\n",
            "Epoch 351/1000\n",
            "9/9 [==============================] - 1s 163ms/step - loss: 0.5843 - accuracy: 0.7305 - val_loss: 0.2762 - val_accuracy: 0.8592\n",
            "Epoch 352/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6097 - accuracy: 0.7234 - val_loss: 0.2691 - val_accuracy: 0.8592\n",
            "Epoch 353/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5750 - accuracy: 0.7447 - val_loss: 0.2671 - val_accuracy: 0.8451\n",
            "Epoch 354/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5690 - accuracy: 0.7340 - val_loss: 0.2712 - val_accuracy: 0.8732\n",
            "Epoch 355/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5672 - accuracy: 0.7482 - val_loss: 0.2629 - val_accuracy: 0.8732\n",
            "Epoch 356/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5962 - accuracy: 0.7340 - val_loss: 0.2588 - val_accuracy: 0.8873\n",
            "Epoch 357/1000\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.5646 - accuracy: 0.7482 - val_loss: 0.2574 - val_accuracy: 0.8732\n",
            "Epoch 358/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5686 - accuracy: 0.7305 - val_loss: 0.2705 - val_accuracy: 0.8310\n",
            "Epoch 359/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5785 - accuracy: 0.7092 - val_loss: 0.2677 - val_accuracy: 0.8592\n",
            "Epoch 360/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5592 - accuracy: 0.7411 - val_loss: 0.2790 - val_accuracy: 0.8592\n",
            "Epoch 361/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5702 - accuracy: 0.7801 - val_loss: 0.2763 - val_accuracy: 0.8451\n",
            "Epoch 362/1000\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 0.5857 - accuracy: 0.7270 - val_loss: 0.2960 - val_accuracy: 0.8451\n",
            "Epoch 363/1000\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.5960 - accuracy: 0.7305 - val_loss: 0.2759 - val_accuracy: 0.8592\n",
            "Epoch 364/1000\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.5765 - accuracy: 0.7340 - val_loss: 0.2614 - val_accuracy: 0.8732\n",
            "Epoch 365/1000\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 0.6008 - accuracy: 0.7305 - val_loss: 0.2683 - val_accuracy: 0.8451\n",
            "Epoch 366/1000\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.5751 - accuracy: 0.7340 - val_loss: 0.2773 - val_accuracy: 0.8310\n",
            "Epoch 367/1000\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.5704 - accuracy: 0.7553 - val_loss: 0.2941 - val_accuracy: 0.8169\n",
            "Epoch 368/1000\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.5908 - accuracy: 0.7589 - val_loss: 0.2616 - val_accuracy: 0.8732\n",
            "Epoch 369/1000\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 0.5820 - accuracy: 0.7447 - val_loss: 0.2658 - val_accuracy: 0.8592\n",
            "Epoch 370/1000\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.5810 - accuracy: 0.7553 - val_loss: 0.2775 - val_accuracy: 0.8310\n",
            "Epoch 371/1000\n",
            "9/9 [==============================] - 1s 56ms/step - loss: 0.5754 - accuracy: 0.7518 - val_loss: 0.2661 - val_accuracy: 0.8592\n",
            "Epoch 372/1000\n",
            "9/9 [==============================] - 0s 56ms/step - loss: 0.5839 - accuracy: 0.7376 - val_loss: 0.2646 - val_accuracy: 0.8592\n",
            "Epoch 373/1000\n",
            "9/9 [==============================] - 0s 52ms/step - loss: 0.5873 - accuracy: 0.7376 - val_loss: 0.2668 - val_accuracy: 0.8592\n",
            "Epoch 374/1000\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.5729 - accuracy: 0.7518 - val_loss: 0.2635 - val_accuracy: 0.8592\n",
            "Epoch 375/1000\n",
            "9/9 [==============================] - 0s 52ms/step - loss: 0.5832 - accuracy: 0.7305 - val_loss: 0.2708 - val_accuracy: 0.8451\n",
            "Epoch 376/1000\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.5856 - accuracy: 0.7270 - val_loss: 0.2717 - val_accuracy: 0.8732\n",
            "Epoch 377/1000\n",
            "9/9 [==============================] - 0s 51ms/step - loss: 0.6144 - accuracy: 0.7199 - val_loss: 0.2688 - val_accuracy: 0.8310\n",
            "Epoch 378/1000\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.5765 - accuracy: 0.7340 - val_loss: 0.2736 - val_accuracy: 0.8451\n",
            "Epoch 379/1000\n",
            "9/9 [==============================] - 0s 51ms/step - loss: 0.5715 - accuracy: 0.7199 - val_loss: 0.2598 - val_accuracy: 0.8592\n",
            "Epoch 380/1000\n",
            "9/9 [==============================] - 0s 57ms/step - loss: 0.5857 - accuracy: 0.7305 - val_loss: 0.2593 - val_accuracy: 0.8732\n",
            "Epoch 381/1000\n",
            "9/9 [==============================] - 0s 51ms/step - loss: 0.5771 - accuracy: 0.7305 - val_loss: 0.2567 - val_accuracy: 0.8732\n",
            "Epoch 382/1000\n",
            "9/9 [==============================] - 1s 60ms/step - loss: 0.5794 - accuracy: 0.7340 - val_loss: 0.2522 - val_accuracy: 0.8732\n",
            "Epoch 383/1000\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.5713 - accuracy: 0.7234 - val_loss: 0.2596 - val_accuracy: 0.8873\n",
            "Epoch 384/1000\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.5870 - accuracy: 0.7305 - val_loss: 0.3916 - val_accuracy: 0.8169\n",
            "Epoch 385/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5612 - accuracy: 0.7376 - val_loss: 0.2722 - val_accuracy: 0.8451\n",
            "Epoch 386/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5780 - accuracy: 0.7447 - val_loss: 0.2612 - val_accuracy: 0.8451\n",
            "Epoch 387/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5699 - accuracy: 0.7199 - val_loss: 0.2583 - val_accuracy: 0.8592\n",
            "Epoch 388/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5648 - accuracy: 0.7340 - val_loss: 0.2652 - val_accuracy: 0.8732\n",
            "Epoch 389/1000\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5906 - accuracy: 0.7553 - val_loss: 0.2620 - val_accuracy: 0.8873\n",
            "Epoch 390/1000\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5658 - accuracy: 0.7660 - val_loss: 0.2658 - val_accuracy: 0.8732\n",
            "Epoch 391/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5892 - accuracy: 0.7270 - val_loss: 0.2662 - val_accuracy: 0.8592\n",
            "Epoch 392/1000\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.5871 - accuracy: 0.7234 - val_loss: 0.2745 - val_accuracy: 0.8451\n",
            "Epoch 393/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5740 - accuracy: 0.7411 - val_loss: 0.2660 - val_accuracy: 0.8592\n",
            "Epoch 394/1000\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5740 - accuracy: 0.7518 - val_loss: 0.2616 - val_accuracy: 0.8732\n",
            "Epoch 395/1000\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5817 - accuracy: 0.7234 - val_loss: 0.2595 - val_accuracy: 0.8592\n",
            "Epoch 396/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5588 - accuracy: 0.7340 - val_loss: 0.2621 - val_accuracy: 0.8592\n",
            "Epoch 397/1000\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.5611 - accuracy: 0.7305 - val_loss: 0.2695 - val_accuracy: 0.8451\n",
            "Epoch 398/1000\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.5659 - accuracy: 0.7553 - val_loss: 0.2658 - val_accuracy: 0.8732\n",
            "Epoch 399/1000\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.5743 - accuracy: 0.7199 - val_loss: 0.2623 - val_accuracy: 0.8732\n",
            "Epoch 400/1000\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5745 - accuracy: 0.7128 - val_loss: 0.2555 - val_accuracy: 0.8732\n",
            "Epoch 401/1000\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.5617 - accuracy: 0.7340 - val_loss: 0.2562 - val_accuracy: 0.8592\n",
            "Epoch 402/1000\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.5857 - accuracy: 0.7234 - val_loss: 0.2625 - val_accuracy: 0.8732\n",
            "Epoch 403/1000\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.5789 - accuracy: 0.7305 - val_loss: 0.2620 - val_accuracy: 0.8592\n",
            "Epoch 404/1000\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.5721 - accuracy: 0.7234 - val_loss: 0.2686 - val_accuracy: 0.8310\n",
            "Epoch 405/1000\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.5634 - accuracy: 0.7305 - val_loss: 0.2682 - val_accuracy: 0.8732\n",
            "Epoch 406/1000\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.5564 - accuracy: 0.7553 - val_loss: 0.2679 - val_accuracy: 0.8451\n",
            "Epoch 407/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5695 - accuracy: 0.7128 - val_loss: 0.2688 - val_accuracy: 0.8592\n",
            "Epoch 408/1000\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.5617 - accuracy: 0.7199 - val_loss: 0.2663 - val_accuracy: 0.8592\n",
            "Epoch 409/1000\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5563 - accuracy: 0.7411 - val_loss: 0.2614 - val_accuracy: 0.8732\n",
            "Epoch 410/1000\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.5812 - accuracy: 0.7163 - val_loss: 0.2618 - val_accuracy: 0.8592\n",
            "Epoch 411/1000\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5665 - accuracy: 0.7482 - val_loss: 0.2584 - val_accuracy: 0.8592\n",
            "Epoch 412/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5859 - accuracy: 0.7340 - val_loss: 0.2608 - val_accuracy: 0.8592\n",
            "Epoch 413/1000\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5927 - accuracy: 0.7447 - val_loss: 0.2551 - val_accuracy: 0.8873\n",
            "Epoch 414/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6152 - accuracy: 0.7057 - val_loss: 0.2566 - val_accuracy: 0.8873\n",
            "Epoch 415/1000\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.6345 - accuracy: 0.7270 - val_loss: 0.2552 - val_accuracy: 0.8732\n",
            "Epoch 416/1000\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.6334 - accuracy: 0.7376 - val_loss: 0.2487 - val_accuracy: 0.8732\n",
            "Epoch 417/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7202 - accuracy: 0.7234 - val_loss: 0.2456 - val_accuracy: 0.8732\n",
            "Epoch 418/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7830 - accuracy: 0.6950 - val_loss: 0.2857 - val_accuracy: 0.8592\n",
            "Epoch 419/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7410 - accuracy: 0.7234 - val_loss: 0.3425 - val_accuracy: 0.8592\n",
            "Epoch 420/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6721 - accuracy: 0.7305 - val_loss: 0.2688 - val_accuracy: 0.8873\n",
            "Epoch 421/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6476 - accuracy: 0.7340 - val_loss: 0.2888 - val_accuracy: 0.8451\n",
            "Epoch 422/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6174 - accuracy: 0.7305 - val_loss: 0.3022 - val_accuracy: 0.8451\n",
            "Epoch 423/1000\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.5776 - accuracy: 0.7624 - val_loss: 0.2774 - val_accuracy: 0.8451\n",
            "Epoch 424/1000\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.5943 - accuracy: 0.7128 - val_loss: 0.2620 - val_accuracy: 0.8592\n",
            "Epoch 425/1000\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.6141 - accuracy: 0.7234 - val_loss: 0.2606 - val_accuracy: 0.8873\n",
            "Epoch 426/1000\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.5876 - accuracy: 0.7624 - val_loss: 0.2611 - val_accuracy: 0.8732\n",
            "Epoch 427/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5666 - accuracy: 0.7624 - val_loss: 0.2661 - val_accuracy: 0.8592\n",
            "Epoch 428/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5816 - accuracy: 0.7376 - val_loss: 0.2712 - val_accuracy: 0.8592\n",
            "Epoch 429/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5969 - accuracy: 0.7021 - val_loss: 0.2711 - val_accuracy: 0.8451\n",
            "Epoch 430/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5651 - accuracy: 0.7482 - val_loss: 0.2670 - val_accuracy: 0.8451\n",
            "Epoch 431/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5756 - accuracy: 0.7660 - val_loss: 0.2724 - val_accuracy: 0.8451\n",
            "Epoch 432/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5872 - accuracy: 0.7234 - val_loss: 0.2749 - val_accuracy: 0.8310\n",
            "Epoch 433/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6412 - accuracy: 0.7092 - val_loss: 0.2596 - val_accuracy: 0.8732\n",
            "Epoch 434/1000\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6740 - accuracy: 0.7411 - val_loss: 0.2608 - val_accuracy: 0.8732\n",
            "Epoch 435/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6098 - accuracy: 0.6986 - val_loss: 0.2751 - val_accuracy: 0.8451\n",
            "Epoch 436/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6122 - accuracy: 0.7305 - val_loss: 0.2755 - val_accuracy: 0.8451\n",
            "Epoch 437/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5784 - accuracy: 0.7340 - val_loss: 0.2816 - val_accuracy: 0.8451\n",
            "Epoch 438/1000\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5691 - accuracy: 0.7447 - val_loss: 0.2718 - val_accuracy: 0.8310\n",
            "Epoch 439/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6018 - accuracy: 0.7305 - val_loss: 0.2715 - val_accuracy: 0.8310\n",
            "Epoch 440/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5901 - accuracy: 0.7411 - val_loss: 0.2657 - val_accuracy: 0.8592\n",
            "Epoch 441/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5591 - accuracy: 0.7305 - val_loss: 0.2659 - val_accuracy: 0.8592\n",
            "Epoch 442/1000\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.5796 - accuracy: 0.7482 - val_loss: 0.2651 - val_accuracy: 0.8451\n",
            "Epoch 443/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5738 - accuracy: 0.7376 - val_loss: 0.2639 - val_accuracy: 0.8592\n",
            "Epoch 444/1000\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5641 - accuracy: 0.7376 - val_loss: 0.2626 - val_accuracy: 0.8592\n",
            "Epoch 445/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5851 - accuracy: 0.7199 - val_loss: 0.2708 - val_accuracy: 0.8451\n",
            "Epoch 446/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.5862 - accuracy: 0.7340 - val_loss: 0.2704 - val_accuracy: 0.8592\n",
            "Epoch 447/1000\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 0.5744 - accuracy: 0.7589 - val_loss: 0.2703 - val_accuracy: 0.8451\n",
            "Epoch 448/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.5738 - accuracy: 0.7270 - val_loss: 0.2633 - val_accuracy: 0.8592\n",
            "Epoch 449/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.5678 - accuracy: 0.7340 - val_loss: 0.2694 - val_accuracy: 0.8451\n",
            "Epoch 450/1000\n",
            "9/9 [==============================] - 0s 51ms/step - loss: 0.5598 - accuracy: 0.7447 - val_loss: 0.2690 - val_accuracy: 0.8732\n",
            "Epoch 451/1000\n",
            "9/9 [==============================] - 1s 55ms/step - loss: 0.5769 - accuracy: 0.7305 - val_loss: 0.2590 - val_accuracy: 0.8592\n",
            "Epoch 452/1000\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 0.5581 - accuracy: 0.7589 - val_loss: 0.2593 - val_accuracy: 0.8592\n",
            "Epoch 453/1000\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.5757 - accuracy: 0.7553 - val_loss: 0.2643 - val_accuracy: 0.8592\n",
            "Epoch 454/1000\n",
            "9/9 [==============================] - 0s 52ms/step - loss: 0.5795 - accuracy: 0.7128 - val_loss: 0.2747 - val_accuracy: 0.8732\n",
            "Epoch 455/1000\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.5577 - accuracy: 0.7553 - val_loss: 0.2815 - val_accuracy: 0.8592\n",
            "Epoch 456/1000\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 0.5594 - accuracy: 0.7163 - val_loss: 0.2750 - val_accuracy: 0.8451\n",
            "Epoch 457/1000\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.5642 - accuracy: 0.7305 - val_loss: 0.2616 - val_accuracy: 0.8592\n",
            "Epoch 458/1000\n",
            "9/9 [==============================] - 0s 52ms/step - loss: 0.5581 - accuracy: 0.7340 - val_loss: 0.2600 - val_accuracy: 0.8732\n",
            "Epoch 459/1000\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.5513 - accuracy: 0.7340 - val_loss: 0.2574 - val_accuracy: 0.8732\n",
            "Epoch 460/1000\n",
            "9/9 [==============================] - 0s 56ms/step - loss: 0.5650 - accuracy: 0.7270 - val_loss: 0.2607 - val_accuracy: 0.8732\n",
            "Epoch 461/1000\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.5569 - accuracy: 0.7376 - val_loss: 0.2648 - val_accuracy: 0.8592\n",
            "Epoch 462/1000\n",
            "9/9 [==============================] - 0s 52ms/step - loss: 0.5625 - accuracy: 0.7163 - val_loss: 0.2685 - val_accuracy: 0.8310\n",
            "Epoch 463/1000\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.5441 - accuracy: 0.7447 - val_loss: 0.2707 - val_accuracy: 0.8310\n",
            "Epoch 464/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.5722 - accuracy: 0.7305 - val_loss: 0.2618 - val_accuracy: 0.8592\n",
            "Epoch 465/1000\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.5608 - accuracy: 0.7305 - val_loss: 0.2636 - val_accuracy: 0.8592\n",
            "Epoch 466/1000\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 0.5575 - accuracy: 0.7128 - val_loss: 0.2624 - val_accuracy: 0.8592\n",
            "Epoch 467/1000\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.5663 - accuracy: 0.7376 - val_loss: 0.2586 - val_accuracy: 0.8732\n",
            "Epoch 468/1000\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.5538 - accuracy: 0.7553 - val_loss: 0.2551 - val_accuracy: 0.8732\n",
            "Epoch 469/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5603 - accuracy: 0.7482 - val_loss: 0.2518 - val_accuracy: 0.8732\n",
            "Epoch 470/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5499 - accuracy: 0.7305 - val_loss: 0.2603 - val_accuracy: 0.8732\n",
            "Epoch 471/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5462 - accuracy: 0.7589 - val_loss: 0.2678 - val_accuracy: 0.8451\n",
            "Epoch 472/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5582 - accuracy: 0.7234 - val_loss: 0.2669 - val_accuracy: 0.8310\n",
            "Epoch 473/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5527 - accuracy: 0.7518 - val_loss: 0.2687 - val_accuracy: 0.8310\n",
            "Epoch 474/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5518 - accuracy: 0.7411 - val_loss: 0.2628 - val_accuracy: 0.8592\n",
            "Epoch 475/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5424 - accuracy: 0.7482 - val_loss: 0.2647 - val_accuracy: 0.8732\n",
            "Epoch 476/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5452 - accuracy: 0.7553 - val_loss: 0.2706 - val_accuracy: 0.8592\n",
            "Epoch 477/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5479 - accuracy: 0.7411 - val_loss: 0.2792 - val_accuracy: 0.8310\n",
            "Epoch 478/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5552 - accuracy: 0.7270 - val_loss: 0.2755 - val_accuracy: 0.8451\n",
            "Epoch 479/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5633 - accuracy: 0.7163 - val_loss: 0.2667 - val_accuracy: 0.8592\n",
            "Epoch 480/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5553 - accuracy: 0.7270 - val_loss: 0.2691 - val_accuracy: 0.8310\n",
            "Epoch 481/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5542 - accuracy: 0.7553 - val_loss: 0.2656 - val_accuracy: 0.8310\n",
            "Epoch 482/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5500 - accuracy: 0.7340 - val_loss: 0.2642 - val_accuracy: 0.8451\n",
            "Epoch 483/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5560 - accuracy: 0.7305 - val_loss: 0.2661 - val_accuracy: 0.8310\n",
            "Epoch 484/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5622 - accuracy: 0.7021 - val_loss: 0.2620 - val_accuracy: 0.8592\n",
            "Epoch 485/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5341 - accuracy: 0.7199 - val_loss: 0.2572 - val_accuracy: 0.8732\n",
            "Epoch 486/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5486 - accuracy: 0.7518 - val_loss: 0.2564 - val_accuracy: 0.8732\n",
            "Epoch 487/1000\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.5591 - accuracy: 0.7305 - val_loss: 0.2635 - val_accuracy: 0.8451\n",
            "Epoch 488/1000\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.5448 - accuracy: 0.7624 - val_loss: 0.2599 - val_accuracy: 0.8732\n",
            "Epoch 489/1000\n",
            "9/9 [==============================] - 1s 62ms/step - loss: 0.5438 - accuracy: 0.7482 - val_loss: 0.2627 - val_accuracy: 0.8732\n",
            "Epoch 490/1000\n",
            "9/9 [==============================] - 0s 57ms/step - loss: 0.5531 - accuracy: 0.7163 - val_loss: 0.2676 - val_accuracy: 0.8732\n",
            "Epoch 491/1000\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.5626 - accuracy: 0.7305 - val_loss: 0.2637 - val_accuracy: 0.8592\n",
            "Epoch 492/1000\n",
            "9/9 [==============================] - 0s 52ms/step - loss: 0.5551 - accuracy: 0.7340 - val_loss: 0.2644 - val_accuracy: 0.8873\n",
            "Epoch 493/1000\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.5465 - accuracy: 0.7447 - val_loss: 0.2621 - val_accuracy: 0.8592\n",
            "Epoch 494/1000\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.5462 - accuracy: 0.7553 - val_loss: 0.2659 - val_accuracy: 0.8451\n",
            "Epoch 495/1000\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.5598 - accuracy: 0.7234 - val_loss: 0.2642 - val_accuracy: 0.8592\n",
            "Epoch 496/1000\n",
            "9/9 [==============================] - 1s 62ms/step - loss: 0.5373 - accuracy: 0.7589 - val_loss: 0.2638 - val_accuracy: 0.8592\n",
            "Epoch 497/1000\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.5421 - accuracy: 0.7589 - val_loss: 0.2673 - val_accuracy: 0.8592\n",
            "Epoch 498/1000\n",
            "9/9 [==============================] - 1s 60ms/step - loss: 0.5553 - accuracy: 0.7482 - val_loss: 0.2626 - val_accuracy: 0.8592\n",
            "Epoch 499/1000\n",
            "9/9 [==============================] - 0s 56ms/step - loss: 0.5544 - accuracy: 0.7340 - val_loss: 0.2699 - val_accuracy: 0.8451\n",
            "Epoch 500/1000\n",
            "9/9 [==============================] - 1s 60ms/step - loss: 0.5595 - accuracy: 0.7199 - val_loss: 0.2687 - val_accuracy: 0.8451\n",
            "Epoch 501/1000\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.5553 - accuracy: 0.7270 - val_loss: 0.2700 - val_accuracy: 0.8451\n",
            "Epoch 502/1000\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.5539 - accuracy: 0.7482 - val_loss: 0.2688 - val_accuracy: 0.8451\n",
            "Epoch 503/1000\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 0.5553 - accuracy: 0.7447 - val_loss: 0.2661 - val_accuracy: 0.8592\n",
            "Epoch 504/1000\n",
            "9/9 [==============================] - 1s 62ms/step - loss: 0.5564 - accuracy: 0.7305 - val_loss: 0.2632 - val_accuracy: 0.8592\n",
            "Epoch 505/1000\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.5602 - accuracy: 0.7305 - val_loss: 0.2629 - val_accuracy: 0.8592\n",
            "Epoch 506/1000\n",
            "9/9 [==============================] - 1s 56ms/step - loss: 0.5540 - accuracy: 0.7340 - val_loss: 0.2685 - val_accuracy: 0.8451\n",
            "Epoch 507/1000\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.5492 - accuracy: 0.7553 - val_loss: 0.2689 - val_accuracy: 0.8451\n",
            "Epoch 508/1000\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 0.5421 - accuracy: 0.7553 - val_loss: 0.2674 - val_accuracy: 0.8451\n",
            "Epoch 509/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5533 - accuracy: 0.7234 - val_loss: 0.2664 - val_accuracy: 0.8592\n",
            "Epoch 510/1000\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.5873 - accuracy: 0.7447 - val_loss: 0.2783 - val_accuracy: 0.8451\n",
            "Epoch 511/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5803 - accuracy: 0.7518 - val_loss: 0.2771 - val_accuracy: 0.8310\n",
            "Epoch 512/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5574 - accuracy: 0.7482 - val_loss: 0.2651 - val_accuracy: 0.8451\n",
            "Epoch 513/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5606 - accuracy: 0.7376 - val_loss: 0.2628 - val_accuracy: 0.8592\n",
            "Epoch 514/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5524 - accuracy: 0.7270 - val_loss: 0.2593 - val_accuracy: 0.8732\n",
            "Epoch 515/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5713 - accuracy: 0.7305 - val_loss: 0.2614 - val_accuracy: 0.8732\n",
            "Epoch 516/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5407 - accuracy: 0.7482 - val_loss: 0.2670 - val_accuracy: 0.8451\n",
            "Epoch 517/1000\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.5653 - accuracy: 0.7199 - val_loss: 0.2694 - val_accuracy: 0.8451\n",
            "Epoch 518/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5479 - accuracy: 0.7482 - val_loss: 0.2664 - val_accuracy: 0.8451\n",
            "Epoch 519/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5645 - accuracy: 0.7270 - val_loss: 0.2573 - val_accuracy: 0.8732\n",
            "Epoch 520/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5463 - accuracy: 0.7518 - val_loss: 0.2653 - val_accuracy: 0.8592\n",
            "Epoch 521/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5566 - accuracy: 0.7340 - val_loss: 0.2674 - val_accuracy: 0.8451\n",
            "Epoch 522/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5388 - accuracy: 0.7553 - val_loss: 0.2718 - val_accuracy: 0.8451\n",
            "Epoch 523/1000\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5531 - accuracy: 0.7411 - val_loss: 0.2754 - val_accuracy: 0.8310\n",
            "Epoch 524/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5445 - accuracy: 0.7553 - val_loss: 0.2680 - val_accuracy: 0.8592\n",
            "Epoch 525/1000\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.5406 - accuracy: 0.7518 - val_loss: 0.2594 - val_accuracy: 0.8592\n",
            "Epoch 526/1000\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.5379 - accuracy: 0.7589 - val_loss: 0.2598 - val_accuracy: 0.8451\n",
            "Epoch 527/1000\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.5321 - accuracy: 0.7695 - val_loss: 0.2568 - val_accuracy: 0.8592\n",
            "Epoch 528/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5456 - accuracy: 0.7624 - val_loss: 0.2607 - val_accuracy: 0.8592\n",
            "Epoch 529/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5626 - accuracy: 0.7270 - val_loss: 0.2631 - val_accuracy: 0.8451\n",
            "Epoch 530/1000\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5574 - accuracy: 0.7270 - val_loss: 0.2590 - val_accuracy: 0.8732\n",
            "Epoch 531/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5642 - accuracy: 0.7270 - val_loss: 0.2638 - val_accuracy: 0.8592\n",
            "Epoch 532/1000\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.5651 - accuracy: 0.7057 - val_loss: 0.2642 - val_accuracy: 0.8592\n",
            "Epoch 533/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.5444 - accuracy: 0.7411 - val_loss: 0.2738 - val_accuracy: 0.8310\n",
            "Epoch 534/1000\n",
            "9/9 [==============================] - 1s 60ms/step - loss: 0.5478 - accuracy: 0.7624 - val_loss: 0.2652 - val_accuracy: 0.8592\n",
            "Epoch 535/1000\n",
            "9/9 [==============================] - 0s 51ms/step - loss: 0.5465 - accuracy: 0.7305 - val_loss: 0.2565 - val_accuracy: 0.8732\n",
            "Epoch 536/1000\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.5510 - accuracy: 0.7447 - val_loss: 0.2543 - val_accuracy: 0.8873\n",
            "Epoch 537/1000\n",
            "9/9 [==============================] - 0s 52ms/step - loss: 0.5379 - accuracy: 0.7447 - val_loss: 0.2593 - val_accuracy: 0.8873\n",
            "Epoch 538/1000\n",
            "9/9 [==============================] - 1s 62ms/step - loss: 0.5483 - accuracy: 0.7234 - val_loss: 0.2623 - val_accuracy: 0.8592\n",
            "Epoch 539/1000\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 0.5451 - accuracy: 0.7553 - val_loss: 0.2629 - val_accuracy: 0.8592\n",
            "Epoch 540/1000\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.5538 - accuracy: 0.7199 - val_loss: 0.2630 - val_accuracy: 0.8592\n",
            "Epoch 541/1000\n",
            "9/9 [==============================] - 0s 51ms/step - loss: 0.5409 - accuracy: 0.7482 - val_loss: 0.2624 - val_accuracy: 0.8592\n",
            "Epoch 542/1000\n",
            "9/9 [==============================] - 1s 60ms/step - loss: 0.5479 - accuracy: 0.7553 - val_loss: 0.2612 - val_accuracy: 0.8732\n",
            "Epoch 543/1000\n",
            "9/9 [==============================] - 0s 52ms/step - loss: 0.5369 - accuracy: 0.7589 - val_loss: 0.2629 - val_accuracy: 0.8592\n",
            "Epoch 544/1000\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.5508 - accuracy: 0.7447 - val_loss: 0.2628 - val_accuracy: 0.8732\n",
            "Epoch 545/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.5663 - accuracy: 0.7163 - val_loss: 0.2633 - val_accuracy: 0.8592\n",
            "Epoch 546/1000\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.5479 - accuracy: 0.7305 - val_loss: 0.2588 - val_accuracy: 0.8732\n",
            "Epoch 547/1000\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.5519 - accuracy: 0.7482 - val_loss: 0.2563 - val_accuracy: 0.8732\n",
            "Epoch 548/1000\n",
            "9/9 [==============================] - 1s 60ms/step - loss: 0.5399 - accuracy: 0.7518 - val_loss: 0.2610 - val_accuracy: 0.8732\n",
            "Epoch 549/1000\n",
            "9/9 [==============================] - 0s 52ms/step - loss: 0.5517 - accuracy: 0.7092 - val_loss: 0.2656 - val_accuracy: 0.8451\n",
            "Epoch 550/1000\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.5578 - accuracy: 0.7447 - val_loss: 0.2650 - val_accuracy: 0.8310\n",
            "Epoch 551/1000\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.5358 - accuracy: 0.7695 - val_loss: 0.2576 - val_accuracy: 0.8732\n",
            "Epoch 552/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5478 - accuracy: 0.7340 - val_loss: 0.2558 - val_accuracy: 0.8873\n",
            "Epoch 553/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5449 - accuracy: 0.7234 - val_loss: 0.2613 - val_accuracy: 0.8873\n",
            "Epoch 554/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5523 - accuracy: 0.7199 - val_loss: 0.2670 - val_accuracy: 0.8592\n",
            "Epoch 555/1000\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.5417 - accuracy: 0.7340 - val_loss: 0.2661 - val_accuracy: 0.8732\n",
            "Epoch 556/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5559 - accuracy: 0.7163 - val_loss: 0.2677 - val_accuracy: 0.8451\n",
            "Epoch 557/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5334 - accuracy: 0.7411 - val_loss: 0.2572 - val_accuracy: 0.8732\n",
            "Epoch 558/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5427 - accuracy: 0.7340 - val_loss: 0.2560 - val_accuracy: 0.8732\n",
            "Epoch 559/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5578 - accuracy: 0.7199 - val_loss: 0.2627 - val_accuracy: 0.8592\n",
            "Epoch 560/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5449 - accuracy: 0.7270 - val_loss: 0.2588 - val_accuracy: 0.8451\n",
            "Epoch 561/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5563 - accuracy: 0.7234 - val_loss: 0.2610 - val_accuracy: 0.8592\n",
            "Epoch 562/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5483 - accuracy: 0.7340 - val_loss: 0.2580 - val_accuracy: 0.8592\n",
            "Epoch 563/1000\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5282 - accuracy: 0.7660 - val_loss: 0.2592 - val_accuracy: 0.8592\n",
            "Epoch 564/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5371 - accuracy: 0.7624 - val_loss: 0.2646 - val_accuracy: 0.8732\n",
            "Epoch 565/1000\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5293 - accuracy: 0.7447 - val_loss: 0.2658 - val_accuracy: 0.8451\n",
            "Epoch 566/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5504 - accuracy: 0.7234 - val_loss: 0.2684 - val_accuracy: 0.8451\n",
            "Epoch 567/1000\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.5512 - accuracy: 0.7376 - val_loss: 0.2618 - val_accuracy: 0.8451\n",
            "Epoch 568/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5534 - accuracy: 0.7411 - val_loss: 0.2616 - val_accuracy: 0.8592\n",
            "Epoch 569/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5477 - accuracy: 0.7411 - val_loss: 0.2657 - val_accuracy: 0.8451\n",
            "Epoch 570/1000\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5503 - accuracy: 0.7447 - val_loss: 0.2641 - val_accuracy: 0.8451\n",
            "Epoch 571/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5561 - accuracy: 0.7199 - val_loss: 0.2594 - val_accuracy: 0.8592\n",
            "Epoch 572/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5516 - accuracy: 0.7411 - val_loss: 0.2571 - val_accuracy: 0.8732\n",
            "Epoch 573/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5509 - accuracy: 0.7376 - val_loss: 0.2590 - val_accuracy: 0.8732\n",
            "Epoch 574/1000\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.5469 - accuracy: 0.7305 - val_loss: 0.2589 - val_accuracy: 0.8732\n",
            "Epoch 575/1000\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.5428 - accuracy: 0.7340 - val_loss: 0.2607 - val_accuracy: 0.8592\n",
            "Epoch 576/1000\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.5431 - accuracy: 0.7376 - val_loss: 0.2680 - val_accuracy: 0.8451\n",
            "Epoch 577/1000\n",
            "9/9 [==============================] - 1s 60ms/step - loss: 0.5448 - accuracy: 0.7411 - val_loss: 0.2719 - val_accuracy: 0.8451\n",
            "Epoch 578/1000\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.5516 - accuracy: 0.7270 - val_loss: 0.2664 - val_accuracy: 0.8592\n",
            "Epoch 579/1000\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.5383 - accuracy: 0.7447 - val_loss: 0.2605 - val_accuracy: 0.8732\n",
            "Epoch 580/1000\n",
            "9/9 [==============================] - 1s 60ms/step - loss: 0.5586 - accuracy: 0.7163 - val_loss: 0.2567 - val_accuracy: 0.8732\n",
            "Epoch 581/1000\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.5406 - accuracy: 0.7553 - val_loss: 0.2594 - val_accuracy: 0.8732\n",
            "Epoch 582/1000\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.5339 - accuracy: 0.7376 - val_loss: 0.2671 - val_accuracy: 0.8310\n",
            "Epoch 583/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.5430 - accuracy: 0.7340 - val_loss: 0.2633 - val_accuracy: 0.8310\n",
            "Epoch 584/1000\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.5363 - accuracy: 0.7340 - val_loss: 0.2640 - val_accuracy: 0.8310\n",
            "Epoch 585/1000\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.5521 - accuracy: 0.7340 - val_loss: 0.2611 - val_accuracy: 0.8732\n",
            "Epoch 586/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.5524 - accuracy: 0.7411 - val_loss: 0.2682 - val_accuracy: 0.8592\n",
            "Epoch 587/1000\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.5581 - accuracy: 0.7305 - val_loss: 0.2707 - val_accuracy: 0.8310\n",
            "Epoch 588/1000\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.5382 - accuracy: 0.7518 - val_loss: 0.2646 - val_accuracy: 0.8592\n",
            "Epoch 589/1000\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.5437 - accuracy: 0.7199 - val_loss: 0.2641 - val_accuracy: 0.8732\n",
            "Epoch 590/1000\n",
            "9/9 [==============================] - 1s 55ms/step - loss: 0.5383 - accuracy: 0.7411 - val_loss: 0.2612 - val_accuracy: 0.8732\n",
            "Epoch 591/1000\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.5477 - accuracy: 0.7305 - val_loss: 0.2651 - val_accuracy: 0.8732\n",
            "Epoch 592/1000\n",
            "9/9 [==============================] - 0s 51ms/step - loss: 0.5477 - accuracy: 0.7482 - val_loss: 0.2620 - val_accuracy: 0.8592\n",
            "Epoch 593/1000\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.5460 - accuracy: 0.7553 - val_loss: 0.2693 - val_accuracy: 0.8592\n",
            "Epoch 594/1000\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.5446 - accuracy: 0.7518 - val_loss: 0.2686 - val_accuracy: 0.8451\n",
            "Epoch 595/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5360 - accuracy: 0.7340 - val_loss: 0.2685 - val_accuracy: 0.8451\n",
            "Epoch 596/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5304 - accuracy: 0.7305 - val_loss: 0.2641 - val_accuracy: 0.8592\n",
            "Epoch 597/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5588 - accuracy: 0.7305 - val_loss: 0.2678 - val_accuracy: 0.8310\n",
            "Epoch 598/1000\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5448 - accuracy: 0.7518 - val_loss: 0.2635 - val_accuracy: 0.8451\n",
            "Epoch 599/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5376 - accuracy: 0.7447 - val_loss: 0.2575 - val_accuracy: 0.8732\n",
            "Epoch 600/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5370 - accuracy: 0.7518 - val_loss: 0.2629 - val_accuracy: 0.8592\n",
            "Epoch 601/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5412 - accuracy: 0.7199 - val_loss: 0.2591 - val_accuracy: 0.8732\n",
            "Epoch 602/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5471 - accuracy: 0.7270 - val_loss: 0.2643 - val_accuracy: 0.8592\n",
            "Epoch 603/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5507 - accuracy: 0.7518 - val_loss: 0.2647 - val_accuracy: 0.8451\n",
            "Epoch 604/1000\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5425 - accuracy: 0.7518 - val_loss: 0.2611 - val_accuracy: 0.8732\n",
            "Epoch 605/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5470 - accuracy: 0.7482 - val_loss: 0.2626 - val_accuracy: 0.8592\n",
            "Epoch 606/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5362 - accuracy: 0.7411 - val_loss: 0.2583 - val_accuracy: 0.8873\n",
            "Epoch 607/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5455 - accuracy: 0.7305 - val_loss: 0.2486 - val_accuracy: 0.8873\n",
            "Epoch 608/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5467 - accuracy: 0.7234 - val_loss: 0.2508 - val_accuracy: 0.9014\n",
            "Epoch 609/1000\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5355 - accuracy: 0.7482 - val_loss: 0.2545 - val_accuracy: 0.8873\n",
            "Epoch 610/1000\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.5444 - accuracy: 0.7128 - val_loss: 0.2618 - val_accuracy: 0.8592\n",
            "Epoch 611/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5292 - accuracy: 0.7482 - val_loss: 0.3047 - val_accuracy: 0.8592\n",
            "Epoch 612/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5586 - accuracy: 0.7270 - val_loss: 0.2650 - val_accuracy: 0.8592\n",
            "Epoch 613/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5633 - accuracy: 0.7482 - val_loss: 0.2699 - val_accuracy: 0.8451\n",
            "Epoch 614/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5521 - accuracy: 0.7411 - val_loss: 0.2732 - val_accuracy: 0.8732\n",
            "Epoch 615/1000\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5561 - accuracy: 0.7305 - val_loss: 0.2588 - val_accuracy: 0.8592\n",
            "Epoch 616/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5511 - accuracy: 0.7234 - val_loss: 0.2595 - val_accuracy: 0.8592\n",
            "Epoch 617/1000\n",
            "9/9 [==============================] - 1s 55ms/step - loss: 0.5479 - accuracy: 0.7270 - val_loss: 0.2544 - val_accuracy: 0.8732\n",
            "Epoch 618/1000\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.5395 - accuracy: 0.7518 - val_loss: 0.2589 - val_accuracy: 0.8592\n",
            "Epoch 619/1000\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.5479 - accuracy: 0.7376 - val_loss: 0.2636 - val_accuracy: 0.8592\n",
            "Epoch 620/1000\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.5354 - accuracy: 0.7199 - val_loss: 0.2685 - val_accuracy: 0.8310\n",
            "Epoch 621/1000\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.5500 - accuracy: 0.7234 - val_loss: 0.2665 - val_accuracy: 0.8451\n",
            "Epoch 622/1000\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.5535 - accuracy: 0.7411 - val_loss: 0.2617 - val_accuracy: 0.8310\n",
            "Epoch 623/1000\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.5495 - accuracy: 0.7447 - val_loss: 0.2620 - val_accuracy: 0.8451\n",
            "Epoch 624/1000\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.5492 - accuracy: 0.7695 - val_loss: 0.2583 - val_accuracy: 0.8873\n",
            "Epoch 625/1000\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.5343 - accuracy: 0.7660 - val_loss: 0.2610 - val_accuracy: 0.8592\n",
            "Epoch 626/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.5386 - accuracy: 0.7518 - val_loss: 0.2611 - val_accuracy: 0.8451\n",
            "Epoch 627/1000\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.5356 - accuracy: 0.7447 - val_loss: 0.2653 - val_accuracy: 0.8310\n",
            "Epoch 628/1000\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.5582 - accuracy: 0.7199 - val_loss: 0.2642 - val_accuracy: 0.8310\n",
            "Epoch 629/1000\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.5484 - accuracy: 0.7411 - val_loss: 0.2576 - val_accuracy: 0.8732\n",
            "Epoch 630/1000\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.5496 - accuracy: 0.7411 - val_loss: 0.2569 - val_accuracy: 0.8732\n",
            "Epoch 631/1000\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.5425 - accuracy: 0.7376 - val_loss: 0.2580 - val_accuracy: 0.8592\n",
            "Epoch 632/1000\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.5380 - accuracy: 0.7447 - val_loss: 0.2572 - val_accuracy: 0.8732\n",
            "Epoch 633/1000\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.5446 - accuracy: 0.7305 - val_loss: 0.2634 - val_accuracy: 0.8592\n",
            "Epoch 634/1000\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.5414 - accuracy: 0.7340 - val_loss: 0.2632 - val_accuracy: 0.8592\n",
            "Epoch 635/1000\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.5508 - accuracy: 0.7340 - val_loss: 0.2685 - val_accuracy: 0.8310\n",
            "Epoch 636/1000\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 0.5310 - accuracy: 0.7730 - val_loss: 0.2682 - val_accuracy: 0.8310\n",
            "Epoch 637/1000\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.5534 - accuracy: 0.7270 - val_loss: 0.2653 - val_accuracy: 0.8310\n",
            "Epoch 638/1000\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.5393 - accuracy: 0.7376 - val_loss: 0.2645 - val_accuracy: 0.8451\n",
            "Epoch 639/1000\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.5385 - accuracy: 0.7660 - val_loss: 0.2623 - val_accuracy: 0.8732\n",
            "Epoch 640/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5477 - accuracy: 0.7411 - val_loss: 0.2590 - val_accuracy: 0.8732\n",
            "Epoch 641/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5503 - accuracy: 0.7376 - val_loss: 0.2539 - val_accuracy: 0.9014\n",
            "Epoch 642/1000\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5448 - accuracy: 0.7553 - val_loss: 0.2581 - val_accuracy: 0.8732\n",
            "Epoch 643/1000\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.5564 - accuracy: 0.7482 - val_loss: 0.2599 - val_accuracy: 0.8732\n",
            "Epoch 644/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5407 - accuracy: 0.7376 - val_loss: 0.2662 - val_accuracy: 0.8451\n",
            "Epoch 645/1000\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.5420 - accuracy: 0.7624 - val_loss: 0.2662 - val_accuracy: 0.8732\n",
            "Epoch 646/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5523 - accuracy: 0.7411 - val_loss: 0.2544 - val_accuracy: 0.8873\n",
            "Epoch 647/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5387 - accuracy: 0.7376 - val_loss: 0.2576 - val_accuracy: 0.8592\n",
            "Epoch 648/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5413 - accuracy: 0.7199 - val_loss: 0.2540 - val_accuracy: 0.8592\n",
            "Epoch 649/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5387 - accuracy: 0.7624 - val_loss: 0.2541 - val_accuracy: 0.8873\n",
            "Epoch 650/1000\n",
            "9/9 [==============================] - 1s 89ms/step - loss: 0.5325 - accuracy: 0.7624 - val_loss: 0.2620 - val_accuracy: 0.8592\n",
            "Epoch 651/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5480 - accuracy: 0.7270 - val_loss: 0.2597 - val_accuracy: 0.8592\n",
            "Epoch 652/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5396 - accuracy: 0.7411 - val_loss: 0.2655 - val_accuracy: 0.8451\n",
            "Epoch 653/1000\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5380 - accuracy: 0.7518 - val_loss: 0.2591 - val_accuracy: 0.8732\n",
            "Epoch 654/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5466 - accuracy: 0.7376 - val_loss: 0.2614 - val_accuracy: 0.8592\n",
            "Epoch 655/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5445 - accuracy: 0.7518 - val_loss: 0.2647 - val_accuracy: 0.8451\n",
            "Epoch 656/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5433 - accuracy: 0.7447 - val_loss: 0.2653 - val_accuracy: 0.8592\n",
            "Epoch 657/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5346 - accuracy: 0.7553 - val_loss: 0.2665 - val_accuracy: 0.8451\n",
            "Epoch 658/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5399 - accuracy: 0.7340 - val_loss: 0.2638 - val_accuracy: 0.8451\n",
            "Epoch 659/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5526 - accuracy: 0.7128 - val_loss: 0.2725 - val_accuracy: 0.8310\n",
            "Epoch 660/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5658 - accuracy: 0.7270 - val_loss: 0.2717 - val_accuracy: 0.8310\n",
            "Epoch 661/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5589 - accuracy: 0.7163 - val_loss: 0.2593 - val_accuracy: 0.8592\n",
            "Epoch 662/1000\n",
            "9/9 [==============================] - 1s 68ms/step - loss: 0.5514 - accuracy: 0.7305 - val_loss: 0.2624 - val_accuracy: 0.8592\n",
            "Epoch 663/1000\n",
            "9/9 [==============================] - 1s 60ms/step - loss: 0.5334 - accuracy: 0.7411 - val_loss: 0.2599 - val_accuracy: 0.8592\n",
            "Epoch 664/1000\n",
            "9/9 [==============================] - 1s 60ms/step - loss: 0.5374 - accuracy: 0.7447 - val_loss: 0.2633 - val_accuracy: 0.8592\n",
            "Epoch 665/1000\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.5571 - accuracy: 0.7199 - val_loss: 0.2672 - val_accuracy: 0.8310\n",
            "Epoch 666/1000\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.5438 - accuracy: 0.7482 - val_loss: 0.2751 - val_accuracy: 0.8451\n",
            "Epoch 667/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.5421 - accuracy: 0.7305 - val_loss: 0.2708 - val_accuracy: 0.8310\n",
            "Epoch 668/1000\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.5575 - accuracy: 0.7270 - val_loss: 0.2703 - val_accuracy: 0.8310\n",
            "Epoch 669/1000\n",
            "9/9 [==============================] - 1s 62ms/step - loss: 0.5376 - accuracy: 0.7411 - val_loss: 0.2675 - val_accuracy: 0.8451\n",
            "Epoch 670/1000\n",
            "9/9 [==============================] - 1s 64ms/step - loss: 0.5506 - accuracy: 0.7270 - val_loss: 0.2687 - val_accuracy: 0.8451\n",
            "Epoch 671/1000\n",
            "9/9 [==============================] - 1s 60ms/step - loss: 0.5493 - accuracy: 0.7234 - val_loss: 0.2642 - val_accuracy: 0.8451\n",
            "Epoch 672/1000\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.5430 - accuracy: 0.7553 - val_loss: 0.2638 - val_accuracy: 0.8592\n",
            "Epoch 673/1000\n",
            "9/9 [==============================] - 1s 64ms/step - loss: 0.5455 - accuracy: 0.7518 - val_loss: 0.2635 - val_accuracy: 0.8451\n",
            "Epoch 674/1000\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.5460 - accuracy: 0.7411 - val_loss: 0.2653 - val_accuracy: 0.8451\n",
            "Epoch 675/1000\n",
            "9/9 [==============================] - 1s 63ms/step - loss: 0.5473 - accuracy: 0.7482 - val_loss: 0.2587 - val_accuracy: 0.8592\n",
            "Epoch 676/1000\n",
            "9/9 [==============================] - 0s 55ms/step - loss: 0.5514 - accuracy: 0.7199 - val_loss: 0.2697 - val_accuracy: 0.8592\n",
            "Epoch 677/1000\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.5377 - accuracy: 0.7553 - val_loss: 0.2671 - val_accuracy: 0.8592\n",
            "Epoch 678/1000\n",
            "9/9 [==============================] - 0s 54ms/step - loss: 0.5395 - accuracy: 0.7589 - val_loss: 0.2646 - val_accuracy: 0.8592\n",
            "Epoch 679/1000\n",
            "9/9 [==============================] - 1s 67ms/step - loss: 0.5383 - accuracy: 0.7411 - val_loss: 0.2576 - val_accuracy: 0.8732\n",
            "Epoch 680/1000\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.5437 - accuracy: 0.7482 - val_loss: 0.2628 - val_accuracy: 0.8451\n",
            "Epoch 681/1000\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.5535 - accuracy: 0.7411 - val_loss: 0.2593 - val_accuracy: 0.8732\n",
            "Epoch 682/1000\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.5403 - accuracy: 0.7482 - val_loss: 0.2606 - val_accuracy: 0.8732\n",
            "Epoch 683/1000\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5451 - accuracy: 0.7518 - val_loss: 0.2558 - val_accuracy: 0.8873\n",
            "Epoch 684/1000\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.5376 - accuracy: 0.7482 - val_loss: 0.2564 - val_accuracy: 0.8873\n",
            "Epoch 685/1000\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.5489 - accuracy: 0.7305 - val_loss: 0.2598 - val_accuracy: 0.8873\n",
            "Epoch 686/1000\n",
            "9/9 [==============================] - 1s 130ms/step - loss: 0.5487 - accuracy: 0.7163 - val_loss: 0.2573 - val_accuracy: 0.8592\n",
            "Epoch 687/1000\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5376 - accuracy: 0.7482 - val_loss: 0.2650 - val_accuracy: 0.8592\n",
            "Epoch 688/1000\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.5454 - accuracy: 0.7340 - val_loss: 0.2697 - val_accuracy: 0.8310\n",
            "Epoch 689/1000\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.5563 - accuracy: 0.7128 - val_loss: 0.2657 - val_accuracy: 0.8310\n",
            "Epoch 690/1000\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.5396 - accuracy: 0.7482 - val_loss: 0.2656 - val_accuracy: 0.8310\n",
            "Epoch 691/1000\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.5489 - accuracy: 0.7270 - val_loss: 0.2655 - val_accuracy: 0.8451\n",
            "Epoch 692/1000\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.5501 - accuracy: 0.7447 - val_loss: 0.2662 - val_accuracy: 0.8592\n",
            "Epoch 693/1000\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.5390 - accuracy: 0.7482 - val_loss: 0.2698 - val_accuracy: 0.8310\n",
            "Epoch 694/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5437 - accuracy: 0.7340 - val_loss: 0.2703 - val_accuracy: 0.8451\n",
            "Epoch 695/1000\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.5349 - accuracy: 0.7340 - val_loss: 0.2645 - val_accuracy: 0.8310\n",
            "Epoch 696/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5465 - accuracy: 0.7305 - val_loss: 0.2609 - val_accuracy: 0.8592\n",
            "Epoch 697/1000\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.5321 - accuracy: 0.7589 - val_loss: 0.2618 - val_accuracy: 0.8592\n",
            "Epoch 698/1000\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.5352 - accuracy: 0.7589 - val_loss: 0.2651 - val_accuracy: 0.8732\n",
            "Epoch 699/1000\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5384 - accuracy: 0.7270 - val_loss: 0.2632 - val_accuracy: 0.8732\n",
            "Epoch 700/1000\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.5405 - accuracy: 0.7270 - val_loss: 0.2690 - val_accuracy: 0.8451\n",
            "Epoch 701/1000\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.5294 - accuracy: 0.7482 - val_loss: 0.2723 - val_accuracy: 0.8310\n",
            "Epoch 702/1000\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.5504 - accuracy: 0.7057 - val_loss: 0.2711 - val_accuracy: 0.8310\n",
            "Epoch 703/1000\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.5343 - accuracy: 0.7518 - val_loss: 0.2698 - val_accuracy: 0.8310\n",
            "Epoch 704/1000\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5300 - accuracy: 0.7660 - val_loss: 0.2645 - val_accuracy: 0.8592\n",
            "Epoch 705/1000\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.5385 - accuracy: 0.7163 - val_loss: 0.2651 - val_accuracy: 0.8732\n",
            "Epoch 706/1000\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.5390 - accuracy: 0.7376 - val_loss: 0.2634 - val_accuracy: 0.8592\n",
            "Epoch 707/1000\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.5505 - accuracy: 0.7234 - val_loss: 0.2668 - val_accuracy: 0.8451\n",
            "Epoch 708/1000\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.5483 - accuracy: 0.7376 - val_loss: 0.2629 - val_accuracy: 0.8592\n",
            "Epoch 709/1000\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.5400 - accuracy: 0.7305 - val_loss: 0.2609 - val_accuracy: 0.8732\n",
            "Epoch 710/1000\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5412 - accuracy: 0.7482 - val_loss: 0.2639 - val_accuracy: 0.8451\n",
            "Epoch 711/1000\n",
            "9/9 [==============================] - 1s 120ms/step - loss: 0.5326 - accuracy: 0.7695 - val_loss: 0.2658 - val_accuracy: 0.8592\n",
            "Epoch 712/1000\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.5438 - accuracy: 0.7553 - val_loss: 0.2666 - val_accuracy: 0.8592\n",
            "Epoch 713/1000\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.5394 - accuracy: 0.7411 - val_loss: 0.2640 - val_accuracy: 0.8592\n",
            "Epoch 714/1000\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.5410 - accuracy: 0.7411 - val_loss: 0.2588 - val_accuracy: 0.8592\n",
            "Epoch 715/1000\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.5411 - accuracy: 0.7234 - val_loss: 0.2604 - val_accuracy: 0.8592\n",
            "Epoch 716/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5452 - accuracy: 0.7270 - val_loss: 0.2643 - val_accuracy: 0.8592\n",
            "Epoch 717/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5302 - accuracy: 0.7376 - val_loss: 0.2704 - val_accuracy: 0.8451\n",
            "Epoch 718/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5466 - accuracy: 0.7305 - val_loss: 0.2635 - val_accuracy: 0.8873\n",
            "Epoch 719/1000\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.5496 - accuracy: 0.7411 - val_loss: 0.2671 - val_accuracy: 0.8592\n",
            "Epoch 720/1000\n",
            "9/9 [==============================] - 1s 66ms/step - loss: 0.5488 - accuracy: 0.7270 - val_loss: 0.2619 - val_accuracy: 0.8732\n",
            "Epoch 721/1000\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.5387 - accuracy: 0.7518 - val_loss: 0.2597 - val_accuracy: 0.8732\n",
            "Epoch 722/1000\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.5365 - accuracy: 0.7447 - val_loss: 0.2630 - val_accuracy: 0.8732\n",
            "Epoch 723/1000\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.5483 - accuracy: 0.7411 - val_loss: 0.2725 - val_accuracy: 0.8592\n",
            "Epoch 724/1000\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.5475 - accuracy: 0.7589 - val_loss: 0.2695 - val_accuracy: 0.8592\n",
            "Epoch 725/1000\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.5361 - accuracy: 0.7270 - val_loss: 0.2716 - val_accuracy: 0.8310\n",
            "Epoch 726/1000\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.5507 - accuracy: 0.7270 - val_loss: 0.2642 - val_accuracy: 0.8592\n",
            "Epoch 727/1000\n",
            "9/9 [==============================] - 1s 56ms/step - loss: 0.5409 - accuracy: 0.7482 - val_loss: 0.2587 - val_accuracy: 0.8873\n",
            "Epoch 728/1000\n",
            "9/9 [==============================] - 1s 63ms/step - loss: 0.5597 - accuracy: 0.7411 - val_loss: 0.2957 - val_accuracy: 0.8592\n",
            "Epoch 729/1000\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.5701 - accuracy: 0.7234 - val_loss: 0.2624 - val_accuracy: 0.8732\n",
            "Epoch 730/1000\n",
            "9/9 [==============================] - 1s 63ms/step - loss: 0.5615 - accuracy: 0.7340 - val_loss: 0.4083 - val_accuracy: 0.7887\n",
            "Epoch 731/1000\n",
            "9/9 [==============================] - 1s 58ms/step - loss: 0.5605 - accuracy: 0.7376 - val_loss: 0.2716 - val_accuracy: 0.8310\n",
            "Epoch 732/1000\n",
            "9/9 [==============================] - 1s 63ms/step - loss: 0.5670 - accuracy: 0.7234 - val_loss: 0.2714 - val_accuracy: 0.8451\n",
            "Epoch 733/1000\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 0.5593 - accuracy: 0.7411 - val_loss: 0.2683 - val_accuracy: 0.8310\n",
            "Epoch 734/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5561 - accuracy: 0.7518 - val_loss: 0.2599 - val_accuracy: 0.8592\n",
            "Epoch 735/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6387 - accuracy: 0.7234 - val_loss: 0.2884 - val_accuracy: 0.8451\n",
            "Epoch 736/1000\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.6674 - accuracy: 0.6986 - val_loss: 0.2643 - val_accuracy: 0.8451\n",
            "Epoch 737/1000\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.5976 - accuracy: 0.7376 - val_loss: 0.2679 - val_accuracy: 0.8592\n",
            "Epoch 738/1000\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.5774 - accuracy: 0.7376 - val_loss: 0.2564 - val_accuracy: 0.8732\n",
            "Epoch 739/1000\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.5674 - accuracy: 0.7163 - val_loss: 0.2668 - val_accuracy: 0.8451\n",
            "Epoch 740/1000\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.5870 - accuracy: 0.7340 - val_loss: 0.2715 - val_accuracy: 0.8451\n",
            "Epoch 741/1000\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6480 - accuracy: 0.7199 - val_loss: 0.2808 - val_accuracy: 0.8310\n",
            "Epoch 742/1000\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5743 - accuracy: 0.7163 - val_loss: 0.2751 - val_accuracy: 0.8451\n",
            "Epoch 743/1000\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5719 - accuracy: 0.7340 - val_loss: 0.2627 - val_accuracy: 0.8732\n",
            "Epoch 744/1000\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.5863 - accuracy: 0.7305 - val_loss: 0.2612 - val_accuracy: 0.8732\n",
            "Epoch 745/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6042 - accuracy: 0.7270 - val_loss: 0.2620 - val_accuracy: 0.8732\n",
            "Epoch 746/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6258 - accuracy: 0.6844 - val_loss: 0.2607 - val_accuracy: 0.8732\n",
            "Epoch 747/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5822 - accuracy: 0.7518 - val_loss: 0.2595 - val_accuracy: 0.8592\n",
            "Epoch 748/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5675 - accuracy: 0.7376 - val_loss: 0.2566 - val_accuracy: 0.8732\n",
            "Epoch 749/1000\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.5667 - accuracy: 0.7234 - val_loss: 0.2651 - val_accuracy: 0.8592\n",
            "Epoch 750/1000\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5662 - accuracy: 0.7447 - val_loss: 0.2724 - val_accuracy: 0.8451\n",
            "Epoch 751/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5429 - accuracy: 0.7376 - val_loss: 0.2709 - val_accuracy: 0.8310\n",
            "Epoch 752/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5566 - accuracy: 0.7270 - val_loss: 0.2616 - val_accuracy: 0.8592\n",
            "Epoch 753/1000\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5564 - accuracy: 0.7270 - val_loss: 0.2602 - val_accuracy: 0.8592\n",
            "Epoch 754/1000\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.5456 - accuracy: 0.7518 - val_loss: 0.2635 - val_accuracy: 0.8592\n",
            "Epoch 755/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5528 - accuracy: 0.7270 - val_loss: 0.2683 - val_accuracy: 0.8451\n",
            "Epoch 756/1000\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.5526 - accuracy: 0.7199 - val_loss: 0.2639 - val_accuracy: 0.8451\n",
            "Epoch 757/1000\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 0.5537 - accuracy: 0.7270 - val_loss: 0.2640 - val_accuracy: 0.8451\n",
            "Epoch 758/1000\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.5421 - accuracy: 0.7553 - val_loss: 0.2569 - val_accuracy: 0.8592\n",
            "Epoch 759/1000\n",
            "9/9 [==============================] - 1s 66ms/step - loss: 0.5471 - accuracy: 0.7234 - val_loss: 0.2638 - val_accuracy: 0.8732\n",
            "Epoch 760/1000\n",
            "9/9 [==============================] - 0s 53ms/step - loss: 0.5425 - accuracy: 0.7660 - val_loss: 0.2646 - val_accuracy: 0.8451\n",
            "Epoch 761/1000\n",
            "9/9 [==============================] - 1s 62ms/step - loss: 0.5393 - accuracy: 0.7695 - val_loss: 0.2670 - val_accuracy: 0.8310\n",
            "Epoch 762/1000\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.5440 - accuracy: 0.7482 - val_loss: 0.2679 - val_accuracy: 0.8310\n",
            "Epoch 763/1000\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.5454 - accuracy: 0.7376 - val_loss: 0.2660 - val_accuracy: 0.8451\n",
            "Epoch 764/1000\n",
            "9/9 [==============================] - 1s 63ms/step - loss: 0.5390 - accuracy: 0.7518 - val_loss: 0.2632 - val_accuracy: 0.8451\n",
            "Epoch 765/1000\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.5399 - accuracy: 0.7447 - val_loss: 0.2633 - val_accuracy: 0.8592\n",
            "Epoch 766/1000\n",
            "9/9 [==============================] - 1s 63ms/step - loss: 0.5384 - accuracy: 0.7376 - val_loss: 0.2611 - val_accuracy: 0.8592\n",
            "Epoch 767/1000\n",
            "9/9 [==============================] - 1s 62ms/step - loss: 0.5289 - accuracy: 0.7624 - val_loss: 0.2624 - val_accuracy: 0.8451\n",
            "Epoch 768/1000\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.5305 - accuracy: 0.7376 - val_loss: 0.2613 - val_accuracy: 0.8451\n",
            "Epoch 769/1000\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.5415 - accuracy: 0.7270 - val_loss: 0.2593 - val_accuracy: 0.8592\n",
            "Epoch 770/1000\n",
            "9/9 [==============================] - 1s 60ms/step - loss: 0.5421 - accuracy: 0.7376 - val_loss: 0.2673 - val_accuracy: 0.8732\n",
            "Epoch 771/1000\n",
            "9/9 [==============================] - 1s 62ms/step - loss: 0.5561 - accuracy: 0.7234 - val_loss: 0.2698 - val_accuracy: 0.8732\n",
            "Epoch 772/1000\n",
            "9/9 [==============================] - 1s 66ms/step - loss: 0.5470 - accuracy: 0.7305 - val_loss: 0.2631 - val_accuracy: 0.8732\n",
            "Epoch 773/1000\n",
            "9/9 [==============================] - 1s 63ms/step - loss: 0.5406 - accuracy: 0.7340 - val_loss: 0.2602 - val_accuracy: 0.8592\n",
            "Epoch 774/1000\n",
            "9/9 [==============================] - 1s 66ms/step - loss: 0.5491 - accuracy: 0.7376 - val_loss: 0.2619 - val_accuracy: 0.8592\n",
            "Epoch 775/1000\n",
            "9/9 [==============================] - 1s 74ms/step - loss: 0.5475 - accuracy: 0.7199 - val_loss: 0.2642 - val_accuracy: 0.8592\n",
            "Epoch 776/1000\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.5343 - accuracy: 0.7270 - val_loss: 0.2678 - val_accuracy: 0.8451\n",
            "Epoch 777/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5479 - accuracy: 0.7340 - val_loss: 0.2683 - val_accuracy: 0.8451\n",
            "Epoch 778/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5514 - accuracy: 0.7305 - val_loss: 0.2625 - val_accuracy: 0.8592\n",
            "Epoch 779/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5424 - accuracy: 0.7234 - val_loss: 0.2647 - val_accuracy: 0.8451\n",
            "Epoch 780/1000\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5356 - accuracy: 0.7553 - val_loss: 0.2589 - val_accuracy: 0.8732\n",
            "Epoch 781/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5512 - accuracy: 0.7163 - val_loss: 0.2610 - val_accuracy: 0.8592\n",
            "Epoch 782/1000\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.5376 - accuracy: 0.7411 - val_loss: 0.2541 - val_accuracy: 0.8732\n",
            "Epoch 783/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5353 - accuracy: 0.7340 - val_loss: 0.2555 - val_accuracy: 0.8592\n",
            "Epoch 784/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5451 - accuracy: 0.7340 - val_loss: 0.2588 - val_accuracy: 0.8592\n",
            "Epoch 785/1000\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5328 - accuracy: 0.7553 - val_loss: 0.2622 - val_accuracy: 0.8592\n",
            "Epoch 786/1000\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5501 - accuracy: 0.7128 - val_loss: 0.2630 - val_accuracy: 0.8451\n",
            "Epoch 787/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5318 - accuracy: 0.7447 - val_loss: 0.2622 - val_accuracy: 0.8451\n",
            "Epoch 788/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5413 - accuracy: 0.7482 - val_loss: 0.2614 - val_accuracy: 0.8310\n",
            "Epoch 789/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5409 - accuracy: 0.7340 - val_loss: 0.2607 - val_accuracy: 0.8451\n",
            "Epoch 790/1000\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5330 - accuracy: 0.7553 - val_loss: 0.2548 - val_accuracy: 0.8873\n",
            "Epoch 791/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5350 - accuracy: 0.7553 - val_loss: 0.2549 - val_accuracy: 0.8873\n",
            "Epoch 792/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5389 - accuracy: 0.7340 - val_loss: 0.2577 - val_accuracy: 0.8592\n",
            "Epoch 793/1000\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.5396 - accuracy: 0.7518 - val_loss: 0.2574 - val_accuracy: 0.8592\n",
            "Epoch 794/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5463 - accuracy: 0.7092 - val_loss: 0.2590 - val_accuracy: 0.8732\n",
            "Epoch 795/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5469 - accuracy: 0.7199 - val_loss: 0.2591 - val_accuracy: 0.8732\n",
            "Epoch 796/1000\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5333 - accuracy: 0.7447 - val_loss: 0.2576 - val_accuracy: 0.8592\n",
            "Epoch 797/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5364 - accuracy: 0.7518 - val_loss: 0.2597 - val_accuracy: 0.8451\n",
            "Epoch 798/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5453 - accuracy: 0.7589 - val_loss: 0.2586 - val_accuracy: 0.8592\n",
            "Epoch 799/1000\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5447 - accuracy: 0.7482 - val_loss: 0.2553 - val_accuracy: 0.8732\n",
            "Epoch 800/1000\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 0.5365 - accuracy: 0.7482 - val_loss: 0.2606 - val_accuracy: 0.8592\n",
            "Epoch 801/1000\n",
            "9/9 [==============================] - 1s 66ms/step - loss: 0.5443 - accuracy: 0.7376 - val_loss: 0.2645 - val_accuracy: 0.8451\n",
            "Epoch 802/1000\n",
            "9/9 [==============================] - 1s 64ms/step - loss: 0.5474 - accuracy: 0.7128 - val_loss: 0.2681 - val_accuracy: 0.8451\n",
            "Epoch 803/1000\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.5374 - accuracy: 0.7411 - val_loss: 0.2647 - val_accuracy: 0.8732\n",
            "Epoch 804/1000\n",
            "9/9 [==============================] - 1s 68ms/step - loss: 0.5377 - accuracy: 0.7482 - val_loss: 0.2633 - val_accuracy: 0.8732\n",
            "Epoch 805/1000\n",
            "9/9 [==============================] - 1s 55ms/step - loss: 0.5348 - accuracy: 0.7553 - val_loss: 0.2584 - val_accuracy: 0.8732\n",
            "Epoch 806/1000\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.5380 - accuracy: 0.7447 - val_loss: 0.2626 - val_accuracy: 0.8451\n",
            "Epoch 807/1000\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.5472 - accuracy: 0.7163 - val_loss: 0.2599 - val_accuracy: 0.8592\n",
            "Epoch 808/1000\n",
            "9/9 [==============================] - 1s 63ms/step - loss: 0.5527 - accuracy: 0.7340 - val_loss: 0.2631 - val_accuracy: 0.8451\n",
            "Epoch 809/1000\n",
            "9/9 [==============================] - 1s 60ms/step - loss: 0.5293 - accuracy: 0.7411 - val_loss: 0.2623 - val_accuracy: 0.8592\n",
            "Epoch 810/1000\n",
            "9/9 [==============================] - 1s 66ms/step - loss: 0.5376 - accuracy: 0.7305 - val_loss: 0.2599 - val_accuracy: 0.8592\n",
            "Epoch 811/1000\n",
            "9/9 [==============================] - 1s 66ms/step - loss: 0.5406 - accuracy: 0.7376 - val_loss: 0.2612 - val_accuracy: 0.8592\n",
            "Epoch 812/1000\n",
            "9/9 [==============================] - 1s 64ms/step - loss: 0.5444 - accuracy: 0.7163 - val_loss: 0.2626 - val_accuracy: 0.8451\n",
            "Epoch 813/1000\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.5403 - accuracy: 0.7305 - val_loss: 0.2621 - val_accuracy: 0.8592\n",
            "Epoch 814/1000\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.5356 - accuracy: 0.7305 - val_loss: 0.2624 - val_accuracy: 0.8592\n",
            "Epoch 815/1000\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.5414 - accuracy: 0.7411 - val_loss: 0.2662 - val_accuracy: 0.8451\n",
            "Epoch 816/1000\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.5499 - accuracy: 0.7447 - val_loss: 0.2670 - val_accuracy: 0.8451\n",
            "Epoch 817/1000\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.5390 - accuracy: 0.7482 - val_loss: 0.2619 - val_accuracy: 0.8732\n",
            "Epoch 818/1000\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.5458 - accuracy: 0.7305 - val_loss: 0.2622 - val_accuracy: 0.8732\n",
            "Epoch 819/1000\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.5410 - accuracy: 0.7340 - val_loss: 0.2559 - val_accuracy: 0.8732\n",
            "Epoch 820/1000\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5494 - accuracy: 0.7447 - val_loss: 0.2542 - val_accuracy: 0.8732\n",
            "Epoch 821/1000\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.5290 - accuracy: 0.7589 - val_loss: 0.2590 - val_accuracy: 0.8592\n",
            "Epoch 822/1000\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.5325 - accuracy: 0.7482 - val_loss: 0.2627 - val_accuracy: 0.8592\n",
            "Epoch 823/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5413 - accuracy: 0.7447 - val_loss: 0.2618 - val_accuracy: 0.8451\n",
            "Epoch 824/1000\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.5320 - accuracy: 0.7482 - val_loss: 0.2619 - val_accuracy: 0.8451\n",
            "Epoch 825/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5475 - accuracy: 0.7128 - val_loss: 0.2642 - val_accuracy: 0.8732\n",
            "Epoch 826/1000\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5404 - accuracy: 0.7270 - val_loss: 0.2582 - val_accuracy: 0.8732\n",
            "Epoch 827/1000\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5355 - accuracy: 0.7447 - val_loss: 0.2621 - val_accuracy: 0.8732\n",
            "Epoch 828/1000\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5442 - accuracy: 0.7376 - val_loss: 0.2594 - val_accuracy: 0.8592\n",
            "Epoch 829/1000\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.5429 - accuracy: 0.7305 - val_loss: 0.2649 - val_accuracy: 0.8451\n",
            "Epoch 830/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5407 - accuracy: 0.7482 - val_loss: 0.2643 - val_accuracy: 0.8310\n",
            "Epoch 831/1000\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5414 - accuracy: 0.7376 - val_loss: 0.2655 - val_accuracy: 0.8310\n",
            "Epoch 832/1000\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5507 - accuracy: 0.7092 - val_loss: 0.2572 - val_accuracy: 0.8732\n",
            "Epoch 833/1000\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5364 - accuracy: 0.7411 - val_loss: 0.2643 - val_accuracy: 0.8592\n",
            "Epoch 834/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5387 - accuracy: 0.7305 - val_loss: 0.2670 - val_accuracy: 0.8451\n",
            "Epoch 835/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5370 - accuracy: 0.7482 - val_loss: 0.2627 - val_accuracy: 0.8592\n",
            "Epoch 836/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5265 - accuracy: 0.7624 - val_loss: 0.2616 - val_accuracy: 0.8592\n",
            "Epoch 837/1000\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.5385 - accuracy: 0.7411 - val_loss: 0.2639 - val_accuracy: 0.8451\n",
            "Epoch 838/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5354 - accuracy: 0.7447 - val_loss: 0.2637 - val_accuracy: 0.8310\n",
            "Epoch 839/1000\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5376 - accuracy: 0.7553 - val_loss: 0.2636 - val_accuracy: 0.8310\n",
            "Epoch 840/1000\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5422 - accuracy: 0.7163 - val_loss: 0.2619 - val_accuracy: 0.8592\n",
            "Epoch 841/1000\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5418 - accuracy: 0.7234 - val_loss: 0.2639 - val_accuracy: 0.8592\n",
            "Epoch 842/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5341 - accuracy: 0.7553 - val_loss: 0.2703 - val_accuracy: 0.8310\n",
            "Epoch 843/1000\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5357 - accuracy: 0.7340 - val_loss: 0.2649 - val_accuracy: 0.8451\n",
            "Epoch 844/1000\n",
            "9/9 [==============================] - 1s 60ms/step - loss: 0.5402 - accuracy: 0.7376 - val_loss: 0.2613 - val_accuracy: 0.8732\n",
            "Epoch 845/1000\n",
            "9/9 [==============================] - 1s 67ms/step - loss: 0.5384 - accuracy: 0.7411 - val_loss: 0.2612 - val_accuracy: 0.8592\n",
            "Epoch 846/1000\n",
            "9/9 [==============================] - 0s 56ms/step - loss: 0.5358 - accuracy: 0.7305 - val_loss: 0.2574 - val_accuracy: 0.8592\n",
            "Epoch 847/1000\n",
            "9/9 [==============================] - 1s 62ms/step - loss: 0.5379 - accuracy: 0.7305 - val_loss: 0.2567 - val_accuracy: 0.8732\n",
            "Epoch 848/1000\n",
            "9/9 [==============================] - 1s 62ms/step - loss: 0.5286 - accuracy: 0.7589 - val_loss: 0.2657 - val_accuracy: 0.8451\n",
            "Epoch 849/1000\n",
            "9/9 [==============================] - 1s 63ms/step - loss: 0.5385 - accuracy: 0.7340 - val_loss: 0.2678 - val_accuracy: 0.8451\n",
            "Epoch 850/1000\n",
            "9/9 [==============================] - 1s 62ms/step - loss: 0.5337 - accuracy: 0.7482 - val_loss: 0.2639 - val_accuracy: 0.8592\n",
            "Epoch 851/1000\n",
            "9/9 [==============================] - 1s 64ms/step - loss: 0.5310 - accuracy: 0.7411 - val_loss: 0.2598 - val_accuracy: 0.8732\n",
            "Epoch 852/1000\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.5399 - accuracy: 0.7128 - val_loss: 0.2608 - val_accuracy: 0.8592\n",
            "Epoch 853/1000\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.5420 - accuracy: 0.7376 - val_loss: 0.2634 - val_accuracy: 0.8451\n",
            "Epoch 854/1000\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.5347 - accuracy: 0.7411 - val_loss: 0.2694 - val_accuracy: 0.8310\n",
            "Epoch 855/1000\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.5348 - accuracy: 0.7482 - val_loss: 0.2715 - val_accuracy: 0.8310\n",
            "Epoch 856/1000\n",
            "9/9 [==============================] - 1s 68ms/step - loss: 0.5400 - accuracy: 0.7518 - val_loss: 0.2702 - val_accuracy: 0.8451\n",
            "Epoch 857/1000\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.5257 - accuracy: 0.7482 - val_loss: 0.2677 - val_accuracy: 0.8592\n",
            "Epoch 858/1000\n",
            "9/9 [==============================] - 1s 63ms/step - loss: 0.5257 - accuracy: 0.7482 - val_loss: 0.2624 - val_accuracy: 0.8592\n",
            "Epoch 859/1000\n",
            "9/9 [==============================] - 1s 66ms/step - loss: 0.5447 - accuracy: 0.7305 - val_loss: 0.2567 - val_accuracy: 0.8732\n",
            "Epoch 860/1000\n",
            "9/9 [==============================] - 1s 64ms/step - loss: 0.5372 - accuracy: 0.7270 - val_loss: 0.2539 - val_accuracy: 0.8732\n",
            "Epoch 861/1000\n",
            "9/9 [==============================] - 1s 62ms/step - loss: 0.5367 - accuracy: 0.7376 - val_loss: 0.2570 - val_accuracy: 0.8732\n",
            "Epoch 862/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5331 - accuracy: 0.7411 - val_loss: 0.2612 - val_accuracy: 0.8592\n",
            "Epoch 863/1000\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5360 - accuracy: 0.7447 - val_loss: 0.2677 - val_accuracy: 0.8310\n",
            "Epoch 864/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5394 - accuracy: 0.7447 - val_loss: 0.2624 - val_accuracy: 0.8592\n",
            "Epoch 865/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5470 - accuracy: 0.7270 - val_loss: 0.2601 - val_accuracy: 0.8592\n",
            "Epoch 866/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5467 - accuracy: 0.7305 - val_loss: 0.2674 - val_accuracy: 0.8451\n",
            "Epoch 867/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5457 - accuracy: 0.7518 - val_loss: 0.2606 - val_accuracy: 0.8592\n",
            "Epoch 868/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5386 - accuracy: 0.7305 - val_loss: 0.2533 - val_accuracy: 0.8592\n",
            "Epoch 869/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5338 - accuracy: 0.7624 - val_loss: 0.2609 - val_accuracy: 0.8592\n",
            "Epoch 870/1000\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5419 - accuracy: 0.7270 - val_loss: 0.2649 - val_accuracy: 0.8451\n",
            "Epoch 871/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5363 - accuracy: 0.7518 - val_loss: 0.2609 - val_accuracy: 0.8873\n",
            "Epoch 872/1000\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5331 - accuracy: 0.7447 - val_loss: 0.2637 - val_accuracy: 0.8451\n",
            "Epoch 873/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5231 - accuracy: 0.7624 - val_loss: 0.2606 - val_accuracy: 0.8592\n",
            "Epoch 874/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5415 - accuracy: 0.7624 - val_loss: 0.2583 - val_accuracy: 0.8592\n",
            "Epoch 875/1000\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5380 - accuracy: 0.7518 - val_loss: 0.2595 - val_accuracy: 0.8592\n",
            "Epoch 876/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5261 - accuracy: 0.7553 - val_loss: 0.2630 - val_accuracy: 0.8592\n",
            "Epoch 877/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5318 - accuracy: 0.7518 - val_loss: 0.2652 - val_accuracy: 0.8451\n",
            "Epoch 878/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5337 - accuracy: 0.7695 - val_loss: 0.2615 - val_accuracy: 0.8592\n",
            "Epoch 879/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5372 - accuracy: 0.7340 - val_loss: 0.2653 - val_accuracy: 0.8451\n",
            "Epoch 880/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5380 - accuracy: 0.7411 - val_loss: 0.2672 - val_accuracy: 0.8310\n",
            "Epoch 881/1000\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5281 - accuracy: 0.7305 - val_loss: 0.2640 - val_accuracy: 0.8310\n",
            "Epoch 882/1000\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.5380 - accuracy: 0.7376 - val_loss: 0.2657 - val_accuracy: 0.8310\n",
            "Epoch 883/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5499 - accuracy: 0.7340 - val_loss: 0.2609 - val_accuracy: 0.8592\n",
            "Epoch 884/1000\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.5430 - accuracy: 0.7553 - val_loss: 0.2572 - val_accuracy: 0.8873\n",
            "Epoch 885/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5413 - accuracy: 0.7411 - val_loss: 0.2578 - val_accuracy: 0.8732\n",
            "Epoch 886/1000\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5410 - accuracy: 0.7447 - val_loss: 0.2616 - val_accuracy: 0.8732\n",
            "Epoch 887/1000\n",
            "9/9 [==============================] - 1s 90ms/step - loss: 0.5442 - accuracy: 0.7376 - val_loss: 0.2658 - val_accuracy: 0.8451\n",
            "Epoch 888/1000\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.5354 - accuracy: 0.7340 - val_loss: 0.2649 - val_accuracy: 0.8732\n",
            "Epoch 889/1000\n",
            "9/9 [==============================] - 1s 63ms/step - loss: 0.5469 - accuracy: 0.7199 - val_loss: 0.2688 - val_accuracy: 0.8451\n",
            "Epoch 890/1000\n",
            "9/9 [==============================] - 1s 67ms/step - loss: 0.5422 - accuracy: 0.7376 - val_loss: 0.2600 - val_accuracy: 0.8732\n",
            "Epoch 891/1000\n",
            "9/9 [==============================] - 1s 59ms/step - loss: 0.5460 - accuracy: 0.7482 - val_loss: 0.2642 - val_accuracy: 0.8592\n",
            "Epoch 892/1000\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.5367 - accuracy: 0.7340 - val_loss: 0.2593 - val_accuracy: 0.8732\n",
            "Epoch 893/1000\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.5478 - accuracy: 0.7447 - val_loss: 0.2650 - val_accuracy: 0.8310\n",
            "Epoch 894/1000\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.5313 - accuracy: 0.7695 - val_loss: 0.3364 - val_accuracy: 0.8310\n",
            "Epoch 895/1000\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.5493 - accuracy: 0.7234 - val_loss: 0.2691 - val_accuracy: 0.8451\n",
            "Epoch 896/1000\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.5265 - accuracy: 0.7482 - val_loss: 0.2649 - val_accuracy: 0.8592\n",
            "Epoch 897/1000\n",
            "9/9 [==============================] - 1s 64ms/step - loss: 0.5381 - accuracy: 0.7340 - val_loss: 0.2728 - val_accuracy: 0.8310\n",
            "Epoch 898/1000\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.5432 - accuracy: 0.7482 - val_loss: 0.2671 - val_accuracy: 0.8451\n",
            "Epoch 899/1000\n",
            "9/9 [==============================] - 1s 62ms/step - loss: 0.5322 - accuracy: 0.7376 - val_loss: 0.2610 - val_accuracy: 0.8592\n",
            "Epoch 900/1000\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.5429 - accuracy: 0.7270 - val_loss: 0.2599 - val_accuracy: 0.8592\n",
            "Epoch 901/1000\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.5549 - accuracy: 0.7624 - val_loss: 0.2689 - val_accuracy: 0.8310\n",
            "Epoch 902/1000\n",
            "9/9 [==============================] - 1s 63ms/step - loss: 0.5372 - accuracy: 0.7482 - val_loss: 0.3000 - val_accuracy: 0.8451\n",
            "Epoch 903/1000\n",
            "9/9 [==============================] - 1s 64ms/step - loss: 0.5567 - accuracy: 0.7482 - val_loss: 0.2691 - val_accuracy: 0.8310\n",
            "Epoch 904/1000\n",
            "9/9 [==============================] - 1s 75ms/step - loss: 0.5657 - accuracy: 0.7376 - val_loss: 0.2587 - val_accuracy: 0.8732\n",
            "Epoch 905/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6244 - accuracy: 0.7305 - val_loss: 0.2646 - val_accuracy: 0.8732\n",
            "Epoch 906/1000\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5550 - accuracy: 0.7411 - val_loss: 0.2634 - val_accuracy: 0.8732\n",
            "Epoch 907/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5729 - accuracy: 0.7199 - val_loss: 0.2682 - val_accuracy: 0.8310\n",
            "Epoch 908/1000\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.5455 - accuracy: 0.7553 - val_loss: 0.2624 - val_accuracy: 0.8592\n",
            "Epoch 909/1000\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.5571 - accuracy: 0.7482 - val_loss: 0.2662 - val_accuracy: 0.8451\n",
            "Epoch 910/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5447 - accuracy: 0.7376 - val_loss: 0.2676 - val_accuracy: 0.8592\n",
            "Epoch 911/1000\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.5454 - accuracy: 0.7305 - val_loss: 0.2672 - val_accuracy: 0.8592\n",
            "Epoch 912/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5395 - accuracy: 0.7695 - val_loss: 0.2618 - val_accuracy: 0.8732\n",
            "Epoch 913/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5465 - accuracy: 0.7305 - val_loss: 0.2669 - val_accuracy: 0.8592\n",
            "Epoch 914/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5392 - accuracy: 0.7340 - val_loss: 0.2647 - val_accuracy: 0.8592\n",
            "Epoch 915/1000\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.5336 - accuracy: 0.7518 - val_loss: 0.2661 - val_accuracy: 0.8451\n",
            "Epoch 916/1000\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.5410 - accuracy: 0.7234 - val_loss: 0.2708 - val_accuracy: 0.8451\n",
            "Epoch 917/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5403 - accuracy: 0.7376 - val_loss: 0.2655 - val_accuracy: 0.8592\n",
            "Epoch 918/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5391 - accuracy: 0.7411 - val_loss: 0.2612 - val_accuracy: 0.8592\n",
            "Epoch 919/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5360 - accuracy: 0.7518 - val_loss: 0.2646 - val_accuracy: 0.8732\n",
            "Epoch 920/1000\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.5344 - accuracy: 0.7234 - val_loss: 0.2672 - val_accuracy: 0.8592\n",
            "Epoch 921/1000\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.5476 - accuracy: 0.7447 - val_loss: 0.2700 - val_accuracy: 0.8310\n",
            "Epoch 922/1000\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.5330 - accuracy: 0.7482 - val_loss: 0.2622 - val_accuracy: 0.8451\n",
            "Epoch 923/1000\n",
            "9/9 [==============================] - 1s 91ms/step - loss: 0.5429 - accuracy: 0.7447 - val_loss: 0.2604 - val_accuracy: 0.8592\n",
            "Epoch 924/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5559 - accuracy: 0.7163 - val_loss: 0.2624 - val_accuracy: 0.8592\n",
            "Epoch 925/1000\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5408 - accuracy: 0.7447 - val_loss: 0.2655 - val_accuracy: 0.8592\n",
            "Epoch 926/1000\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.5426 - accuracy: 0.7376 - val_loss: 0.2654 - val_accuracy: 0.8592\n",
            "Epoch 927/1000\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.5362 - accuracy: 0.7553 - val_loss: 0.2686 - val_accuracy: 0.8310\n",
            "Epoch 928/1000\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.5380 - accuracy: 0.7340 - val_loss: 0.2603 - val_accuracy: 0.8592\n",
            "Epoch 929/1000\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.5426 - accuracy: 0.7270 - val_loss: 0.2626 - val_accuracy: 0.8451\n",
            "Epoch 930/1000\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5316 - accuracy: 0.7624 - val_loss: 0.2632 - val_accuracy: 0.8592\n",
            "Epoch 931/1000\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.5295 - accuracy: 0.7766 - val_loss: 0.2652 - val_accuracy: 0.8310\n",
            "Epoch 932/1000\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.5447 - accuracy: 0.7553 - val_loss: 0.2648 - val_accuracy: 0.8310\n",
            "Epoch 933/1000\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.5356 - accuracy: 0.7553 - val_loss: 0.2596 - val_accuracy: 0.8592\n",
            "Epoch 934/1000\n",
            "9/9 [==============================] - 1s 72ms/step - loss: 0.5382 - accuracy: 0.7411 - val_loss: 0.2632 - val_accuracy: 0.8592\n",
            "Epoch 935/1000\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.5442 - accuracy: 0.7340 - val_loss: 0.2594 - val_accuracy: 0.8592\n",
            "Epoch 936/1000\n",
            "9/9 [==============================] - 1s 66ms/step - loss: 0.5314 - accuracy: 0.7411 - val_loss: 0.2612 - val_accuracy: 0.8592\n",
            "Epoch 937/1000\n",
            "9/9 [==============================] - 1s 62ms/step - loss: 0.5456 - accuracy: 0.7340 - val_loss: 0.2707 - val_accuracy: 0.8310\n",
            "Epoch 938/1000\n",
            "9/9 [==============================] - 1s 57ms/step - loss: 0.5368 - accuracy: 0.7376 - val_loss: 0.2724 - val_accuracy: 0.8310\n",
            "Epoch 939/1000\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.5377 - accuracy: 0.7199 - val_loss: 0.2652 - val_accuracy: 0.8451\n",
            "Epoch 940/1000\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 0.5416 - accuracy: 0.7411 - val_loss: 0.2609 - val_accuracy: 0.8592\n",
            "Epoch 941/1000\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 0.5280 - accuracy: 0.7411 - val_loss: 0.2623 - val_accuracy: 0.8592\n",
            "Epoch 942/1000\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 0.5378 - accuracy: 0.7553 - val_loss: 0.2630 - val_accuracy: 0.8451\n",
            "Epoch 943/1000\n",
            "9/9 [==============================] - 1s 76ms/step - loss: 0.5351 - accuracy: 0.7234 - val_loss: 0.2649 - val_accuracy: 0.8592\n",
            "Epoch 944/1000\n",
            "9/9 [==============================] - 2s 256ms/step - loss: 0.5387 - accuracy: 0.7411 - val_loss: 0.2633 - val_accuracy: 0.8451\n",
            "Epoch 945/1000\n",
            "9/9 [==============================] - 1s 146ms/step - loss: 0.5269 - accuracy: 0.7447 - val_loss: 0.2654 - val_accuracy: 0.8451\n",
            "Epoch 946/1000\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.5468 - accuracy: 0.7163 - val_loss: 0.2616 - val_accuracy: 0.8592\n",
            "Epoch 947/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5356 - accuracy: 0.7482 - val_loss: 0.2601 - val_accuracy: 0.8592\n",
            "Epoch 948/1000\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5424 - accuracy: 0.7447 - val_loss: 0.2646 - val_accuracy: 0.8592\n",
            "Epoch 949/1000\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.5373 - accuracy: 0.7376 - val_loss: 0.2614 - val_accuracy: 0.8592\n",
            "Epoch 950/1000\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5379 - accuracy: 0.7553 - val_loss: 0.2715 - val_accuracy: 0.8310\n",
            "Epoch 951/1000\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.5466 - accuracy: 0.7340 - val_loss: 0.2640 - val_accuracy: 0.8451\n",
            "Epoch 952/1000\n",
            "9/9 [==============================] - 1s 122ms/step - loss: 0.5252 - accuracy: 0.7447 - val_loss: 0.2622 - val_accuracy: 0.8732\n",
            "Epoch 953/1000\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.5397 - accuracy: 0.7518 - val_loss: 0.2628 - val_accuracy: 0.8451\n",
            "Epoch 954/1000\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.5404 - accuracy: 0.7128 - val_loss: 0.2647 - val_accuracy: 0.8451\n",
            "Epoch 955/1000\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5381 - accuracy: 0.7482 - val_loss: 0.2619 - val_accuracy: 0.8592\n",
            "Epoch 956/1000\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5395 - accuracy: 0.7376 - val_loss: 0.2608 - val_accuracy: 0.8732\n",
            "Epoch 957/1000\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5376 - accuracy: 0.7376 - val_loss: 0.2635 - val_accuracy: 0.8732\n",
            "Epoch 958/1000\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5369 - accuracy: 0.7447 - val_loss: 0.2658 - val_accuracy: 0.8451\n",
            "Epoch 959/1000\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5398 - accuracy: 0.7376 - val_loss: 0.2684 - val_accuracy: 0.8451\n",
            "Epoch 960/1000\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.5386 - accuracy: 0.7589 - val_loss: 0.2635 - val_accuracy: 0.8592\n",
            "Epoch 961/1000\n",
            "9/9 [==============================] - 1s 123ms/step - loss: 0.5472 - accuracy: 0.7340 - val_loss: 0.2594 - val_accuracy: 0.8592\n",
            "Epoch 962/1000\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.5433 - accuracy: 0.7305 - val_loss: 0.2672 - val_accuracy: 0.8310\n",
            "Epoch 963/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5317 - accuracy: 0.7589 - val_loss: 0.2659 - val_accuracy: 0.8451\n",
            "Epoch 964/1000\n",
            "9/9 [==============================] - 1s 116ms/step - loss: 0.5406 - accuracy: 0.7340 - val_loss: 0.2628 - val_accuracy: 0.8310\n",
            "Epoch 965/1000\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.5491 - accuracy: 0.7057 - val_loss: 0.2618 - val_accuracy: 0.8592\n",
            "Epoch 966/1000\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.5361 - accuracy: 0.7482 - val_loss: 0.2637 - val_accuracy: 0.8310\n",
            "Epoch 967/1000\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.5309 - accuracy: 0.7411 - val_loss: 0.2672 - val_accuracy: 0.8310\n",
            "Epoch 968/1000\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.5438 - accuracy: 0.7376 - val_loss: 0.2686 - val_accuracy: 0.8310\n",
            "Epoch 969/1000\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5313 - accuracy: 0.7553 - val_loss: 0.2630 - val_accuracy: 0.8592\n",
            "Epoch 970/1000\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.5374 - accuracy: 0.7447 - val_loss: 0.2622 - val_accuracy: 0.8592\n",
            "Epoch 971/1000\n",
            "9/9 [==============================] - 1s 110ms/step - loss: 0.5342 - accuracy: 0.7376 - val_loss: 0.2608 - val_accuracy: 0.8592\n",
            "Epoch 972/1000\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.5488 - accuracy: 0.7092 - val_loss: 0.2598 - val_accuracy: 0.8592\n",
            "Epoch 973/1000\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.5461 - accuracy: 0.7270 - val_loss: 0.2617 - val_accuracy: 0.8451\n",
            "Epoch 974/1000\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5440 - accuracy: 0.7411 - val_loss: 0.2612 - val_accuracy: 0.8451\n",
            "Epoch 975/1000\n",
            "9/9 [==============================] - 1s 118ms/step - loss: 0.5378 - accuracy: 0.7340 - val_loss: 0.2606 - val_accuracy: 0.8732\n",
            "Epoch 976/1000\n",
            "9/9 [==============================] - 1s 121ms/step - loss: 0.5384 - accuracy: 0.7553 - val_loss: 0.2572 - val_accuracy: 0.8592\n",
            "Epoch 977/1000\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5310 - accuracy: 0.7589 - val_loss: 0.2585 - val_accuracy: 0.8592\n",
            "Epoch 978/1000\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.5516 - accuracy: 0.7305 - val_loss: 0.2593 - val_accuracy: 0.8592\n",
            "Epoch 979/1000\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.5603 - accuracy: 0.7163 - val_loss: 0.2649 - val_accuracy: 0.8451\n",
            "Epoch 980/1000\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.5595 - accuracy: 0.7376 - val_loss: 0.2638 - val_accuracy: 0.8451\n",
            "Epoch 981/1000\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.5503 - accuracy: 0.7270 - val_loss: 0.2570 - val_accuracy: 0.8732\n",
            "Epoch 982/1000\n",
            "9/9 [==============================] - 1s 124ms/step - loss: 0.5379 - accuracy: 0.7411 - val_loss: 0.2609 - val_accuracy: 0.8732\n",
            "Epoch 983/1000\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.5507 - accuracy: 0.7234 - val_loss: 0.2613 - val_accuracy: 0.8592\n",
            "Epoch 984/1000\n",
            "9/9 [==============================] - 1s 127ms/step - loss: 0.5400 - accuracy: 0.7482 - val_loss: 0.2622 - val_accuracy: 0.8592\n",
            "Epoch 985/1000\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.5448 - accuracy: 0.7305 - val_loss: 0.2605 - val_accuracy: 0.8592\n",
            "Epoch 986/1000\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5389 - accuracy: 0.7411 - val_loss: 0.2590 - val_accuracy: 0.8732\n",
            "Epoch 987/1000\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5424 - accuracy: 0.7376 - val_loss: 0.2586 - val_accuracy: 0.8592\n",
            "Epoch 988/1000\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.5355 - accuracy: 0.7447 - val_loss: 0.2629 - val_accuracy: 0.8592\n",
            "Epoch 989/1000\n",
            "9/9 [==============================] - 1s 70ms/step - loss: 0.5400 - accuracy: 0.7376 - val_loss: 0.2667 - val_accuracy: 0.8451\n",
            "Epoch 990/1000\n",
            "9/9 [==============================] - 1s 67ms/step - loss: 0.5314 - accuracy: 0.7482 - val_loss: 0.2689 - val_accuracy: 0.8451\n",
            "Epoch 991/1000\n",
            "9/9 [==============================] - 1s 71ms/step - loss: 0.5425 - accuracy: 0.7340 - val_loss: 0.2649 - val_accuracy: 0.8732\n",
            "Epoch 992/1000\n",
            "9/9 [==============================] - 1s 62ms/step - loss: 0.5940 - accuracy: 0.7482 - val_loss: 0.2667 - val_accuracy: 0.8592\n",
            "Epoch 993/1000\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.5410 - accuracy: 0.7482 - val_loss: 0.2607 - val_accuracy: 0.8592\n",
            "Epoch 994/1000\n",
            "9/9 [==============================] - 1s 64ms/step - loss: 0.5824 - accuracy: 0.7376 - val_loss: 0.2620 - val_accuracy: 0.8592\n",
            "Epoch 995/1000\n",
            "9/9 [==============================] - 1s 65ms/step - loss: 0.5322 - accuracy: 0.7518 - val_loss: 0.2623 - val_accuracy: 0.8592\n",
            "Epoch 996/1000\n",
            "9/9 [==============================] - 1s 69ms/step - loss: 0.5502 - accuracy: 0.7553 - val_loss: 0.2633 - val_accuracy: 0.8592\n",
            "Epoch 997/1000\n",
            "9/9 [==============================] - 1s 68ms/step - loss: 0.5379 - accuracy: 0.7660 - val_loss: 0.2609 - val_accuracy: 0.8592\n",
            "Epoch 998/1000\n",
            "9/9 [==============================] - 1s 61ms/step - loss: 0.5432 - accuracy: 0.7411 - val_loss: 0.2659 - val_accuracy: 0.8310\n",
            "Epoch 999/1000\n",
            "9/9 [==============================] - 1s 68ms/step - loss: 0.5319 - accuracy: 0.7482 - val_loss: 0.2694 - val_accuracy: 0.8310\n",
            "Epoch 1000/1000\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 0.5346 - accuracy: 0.7589 - val_loss: 0.2658 - val_accuracy: 0.8310\n"
          ]
        }
      ],
      "source": [
        "\n",
        "history = model.fit(x_train, x_label, validation_data=(y_train, y_label),\n",
        "                    batch_size=32, epochs=1000, callbacks=[MyCallback()])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "zgyxqdBB4bp8",
        "outputId": "ce8c4da2-4a26-44bc-d7b3-a1ee6aa6e0f5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_training_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDiWvHPq4iqI",
        "outputId": "24a9cda8-3462-4923-9313-34546d295cbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: sebutkan pengertian kuhp\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "Label: qna 9\n",
            "Chatbot: Istilah tindak pidana berasal dari bahasa Belanda \"Strafbaar feit\" yang memiliki banyak istilah lain, yaitu delik yang jika disimpulkan kedua istilah tersebut memiliki arti yang sama dengan perbuatan yang dapat/boleh dihukum, peristiwa pidana, perbuatan pidana, dan tindak pidana.\n",
            "\n",
            "Jadi, tindak pidana merupakan perbuatan yang dilakukan seseoran dengan melakukan suatu kejahatan atau pelanggaran pidana yang merugikan kepentingan orang lain atau merugikan kepentingan umum.\n",
            "User: apa itu pidana?\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "Label: qna 9\n",
            "Chatbot: Istilah tindak pidana berasal dari bahasa Belanda \"Strafbaar feit\" yang memiliki banyak istilah lain, yaitu delik yang jika disimpulkan kedua istilah tersebut memiliki arti yang sama dengan perbuatan yang dapat/boleh dihukum, peristiwa pidana, perbuatan pidana, dan tindak pidana.\n",
            "\n",
            "Jadi, tindak pidana merupakan perbuatan yang dilakukan seseoran dengan melakukan suatu kejahatan atau pelanggaran pidana yang merugikan kepentingan orang lain atau merugikan kepentingan umum.\n",
            "User: pemufakatan jahat itu apa\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Label: qna 10\n",
            "Chatbot: Pemufakatan jahat diatur dalam Pasal 13 UU 1/2023 baru, pasal ini berisikan:\n",
            "(1) Permufakatan jahat terjadi jika 2 (dua) orang atau lebih bersepakat untuk melakukan Tindak Pidana.\n",
            "(2) Pemufakatan jahat melakukan Tindak Pidana dipidana jika ditentukan secara tegas dalam Undang-Undang.\n",
            "(3) Pidana untuk pemufakatan jahat melakukan tindak pidana paling banyak 1/3 (satu per tiga) dari maksimum ancaman pidana pokok untuk tindak pidana yang bersangkutan.\n",
            "(4) Permufakatan jahat melakukan Tindak Pidana yang diancam dengan pidana mati atau pidana penjara seumur hidup dipidana dengan pidana penjara paling lama 7 (tujuh) tahun.\n",
            "(5) Pidana tambahan untuk permufakatan jahat melakukan Tindak Pidana sama dengan pidana tambahan untuk Tindak Pidana yang bersangkutan.\n",
            "User: Apa motivasi utama dalam menyusun KUHP yang baru?\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "Label: qna 1\n",
            "Chatbot: Tujuan utama dari pembentukan Kitab Undang-Undang Hukum Pidana (KUHP) yang baru adalah diperlukan adanya pembaharuan hukum yaitu demokratisasi hukum pidana karena KUHP lama merupakan produk hukum pemerintahan zaman kolonial Hindia Belanda. Pada KUHP baru pemidanaannya berorientasi pada pencegahan bukan penjatuhan hukum. Salah satu contohnya, yaitu diperhatikannya atau diaturnya hak-hak korban disamping proses hukum terhadap kejahatan yang dilakukan pelaku. Pembaharuan ini dilakukan dengan alasan filosofis, politis, sosiologis, dan praktis.  \n",
            "\n",
            "Filosofis: KUHP lama disusun oleh pemerintah kolonial Belanda dan tidak sesuai dengan landasan filosofis Indonesia.\n",
            "\n",
            "Sosiologis: Banyak pasal KUHP lama yang tidak lagi sesuai dengan nilai-nilai yang berlaku dalam masyarakat Indonesia modern, dan adanya kemajuan ilmu pengetahuan dan teknologi membuat berbagai pengaturan dalam KUHP menjadi tidak memadai dan ketinggalan zaman.\n"
          ]
        }
      ],
      "source": [
        "chatbot_test()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
